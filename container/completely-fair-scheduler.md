# CFS - å®Œå…¨å…¬å¹³è°ƒåº¦å™¨

## åº

æœ€æ—©æ¥è§¦æ“ä½œç³»ç»Ÿè¿™ä¸ªæ¦‚å¿µçš„æ—¶å€™ï¼Œå…¶ä¸­å®ƒçš„ä¸€ä¸ªä½œç”¨å°±æœ‰ è¿›ç¨‹è°ƒåº¦ï¼Œè¿™ä¹Ÿæ˜¯æœ€æ ¸å¿ƒçš„ä¸€ä¸ªåœ°æ–¹ï¼Œä½†æ˜¯ä¹Ÿæ˜¯æœ€æ¯”è¾ƒéš¾æ‡‚çš„åœ°æ–¹ï¼Œå› ä¸ºå…‰è¦ç†è§£ä¸€ä¸ªè¿›ç¨‹è°ƒåº¦çš„åˆ‡æ¢æœ¬è´¨ï¼Œç‰¹åˆ«æ˜¯ä¸€ä¸ªæ–°æ‰‹ï¼Œä¼°è®¡å°±èƒ½èŠ±è´¹ä¸€ä¸ªæ˜ŸæœŸï¼Œå¦‚æœæ˜¯å¯¹æ ˆå¾ˆç†Ÿæ‚‰çš„å¯èƒ½èƒ½å¾ˆå¿«æŒæ¡ï¼Œä½†æ˜¯é™¤äº†è¿›ç¨‹åˆ‡æ¢ï¼Œè¿›ç¨‹è°ƒåº¦çš„å…³é”®è¿˜åœ¨äºè¿›ç¨‹è°ƒåº¦çš„ç®—æ³•ï¼Œè¿™ä¹Ÿæ˜¯æœ€æ ¸å¿ƒçš„åœ°æ–¹ï¼Œä¹‹æ‰€ä»¥åˆ°äº†å¦‚ä»Šæ‰æ¥å­¦ä¹ ï¼Œä¹Ÿæ˜¯æœ‰ç‚¹å› ä¸ºç•éš¾çš„å¿ƒç†ã€‚

ä¸è¿‡è¿Ÿæ—©æ˜¯è¦é¢å¯¹çš„ï¼Œæ‰€ä»¥å¦‚ä»Šè®©æˆ‘ä»¬æ¥èµ°è¿›ä¸€ä¸ªå…·ä½“çš„è¿›ç¨‹è°ƒåº¦çš„ç®—æ³•ï¼Œè¿›ç¨‹åˆ‡æ¢æ˜¯æ¶‰åŠåˆ°å…·ä½“çš„æ¶æ„çš„ï¼Œå½“ç„¶ä¸æ˜¯è¿™ç¯‡æ–‡ç« çš„ä¸»é¢˜äº†ã€‚

{% hint style="info" %}
è¿™ç¯‡æ–‡ç« ä¸åŒºåˆ†è¿›ç¨‹å’Œçº¿ç¨‹çš„åŒºåˆ«ï¼Œçº¿ç¨‹å°±å½“ä½œä¸€ä¸ªè¿›ç¨‹ï¼Œè¿™é‡Œæ‰€è¯´çš„è¿›ç¨‹å°±æ˜¯ä¸€ä¸ªå¯è°ƒåº¦çš„å•ä½ã€‚
{% endhint %}

### è°ƒåº¦ç®—æ³•çš„å‘å±•è¿‡ç¨‹

æˆ‘ä¸æ˜¯è·Ÿç€æ—©æœŸLinuxä¸€èµ·æˆé•¿çš„å­©å­ï¼Œè¿™ç‚¹æˆ‘ä¹Ÿæ²¡æœ‰å‘è¨€æƒï¼ŒLinux è¯ç”Ÿçš„æ—¶å€™æˆ‘è¿˜æ²¡æœ‰å‡ºç”Ÿï¼Œä½†æ˜¯ IBM æœ‰ä¸€ç¯‡[æ–‡ç« ](https://developer.ibm.com/tutorials/l-completely-fair-scheduler/)ä»‹ç»çš„ä¸é”™ã€‚

> Early Linux schedulers used minimal designs, obviously not focused on massive architectures with many processors or even hyperthreading. The 1.2 Linux scheduler used a circular queue for runnable task management that operated with a round-robin scheduling policy. This scheduler was efficient for adding and removing processes \(with a lock to protect the structure\). In short, the scheduler wasnâ€™t complex but was simple and fast.
>
> Linux version 2.2 introduced the idea of scheduling classes, permitting scheduling policies for real-time tasks, non-preemptible tasks, and non-real-time tasks. The 2.2 scheduler also included support for symmetric multiprocessing \(SMP\).
>
> The 2.4 kernel included a relatively simple scheduler that operated in O\(N\) time \(as it iterated over every task during a scheduling event\). The 2.4 scheduler divided time into epochs, and within each epoch, every task was allowed to execute up to its time slice. If a task did not use all of its time slice, then half of the remaining time slice was added to the new time slice to allow it to execute longer in the next epoch. The scheduler would simply iterate over the tasks, applying a goodness function \(metric\) to determine which task to execute next. Although this approach was relatively simple, it was relatively inefficient, lacked scalability, and was weak for real-time systems. It also lacked features to exploit new hardware architectures such as multi-core processors.
>
> The early 2.6 scheduler, called the _O\(1\) scheduler,_ was designed to solve many of the problems with the 2.4 schedulerâ€”namely, the scheduler was not required to iterate the entire task list to identify the next task to schedule \(resulting in its name, _O\(1\),_ which meant that it was much more efficient and much more scalable\). The O\(1\) scheduler kept track of runnable tasks in a run queue \(actually, two run queues for each priority levelâ€”one for active and one for expired tasks\), which meant that to identify the task to execute next, the scheduler simply needed to dequeue the next task off the specific active per-priority run queue. The O\(1\) scheduler was much more scalable and incorporated interactivity metrics with numerous heuristics to determine whether tasks were I/O-bound or processor-bound. But the O\(1\) scheduler became unwieldy in the kernel. The large mass of code needed to calculate heuristics was fundamentally difficult to manage and, for the purist, lacked algorithmic substance.
>
> Given the issues facing the O\(1\) scheduler and other external pressures, something needed to change. That change came in the way of a kernel patch from Con Kolivas, with his Rotating Staircase Deadline Scheduler \(RSDL\), which included his earlier work on the staircase scheduler. The result of this work was a simply designed scheduler that incorporated fairness with bounded latency. Kolivasâ€™ scheduler impressed many \(with calls to incorporate it into the current 2.6.21 mainline kernel\), so it was clear that a scheduler change was on the way. Ingo Molnar, the creator of the O\(1\) scheduler, then developed the CFS based around some of the ideas from Kolivasâ€™ work. Letâ€™s dig into the CFS to see how it operates at a high level.

ä¸äº†è§£ä¹Ÿæ— ä¼¤å¤§é›…ï¼Œå› ä¸ºè¿›ç¨‹ç®—æ³•éƒ½æ˜¯ä¸æ—¶ä¿±è¿›çš„ï¼Œéƒ½æ˜¯éšç€ç¡¬ä»¶çš„å‘å±•å†åšå‡ºå…·ä½“çš„è°ƒæ•´ï¼Œåœ¨æœ€æ—©çš„ Linuxï¼Œæ¯ä¸ªè¿›ç¨‹éƒ½æ‹¥æœ‰ä¸€ä¸ªå¹³ç­‰çš„æ—¶é—´ç‰‡ï¼Œä½†æ˜¯æ ¹æ®ä¸€äº›ä¼˜å…ˆçº§ï¼Œæ¥æ”¹å˜è°ƒåº¦é¡ºåºï¼Œè¿™äº›æ¦‚å¿µåˆ°å¦‚ä»Šéƒ½æ²¡æœ‰æ”¹å˜ï¼Œå”¯ä¸€ä¸€ç›´åœ¨å˜çš„å°±æ˜¯ï¼ŒCPU çš„æ€§èƒ½ä¸€ç›´åœ¨æå‡ï¼Œæ‰€ä»¥å•ä½æ—¶é—´æ‰§è¡Œçš„æŒ‡ä»¤ä¹Ÿé£é€Ÿçš„æå‡ï¼Œè¿™ä¹Ÿç»™äº†è¿›ç¨‹çš„æ—¶é—´ç‰‡å¯ä»¥è¢«**åˆ†å‰²çš„æ›´çŸ­**ï¼Œæ‰€ä»¥çœ‹èµ·æ¥_**åŒæ—¶æ‰§è¡Œçš„è¿›ç¨‹**_å˜å¤šäº†ã€‚

å¯¹äº†ï¼Œç»´åŸºä¸Šæœ‰ä¸€ä¸ª[ç›®å½•](https://en.wikipedia.org/wiki/Category:Linux_kernel_process_schedulers)ï¼Œæ˜¯å†…æ ¸å­˜åœ¨è¿‡çš„è°ƒåº¦ç®—æ³•ï¼Œå¯ä»¥äº†è§£åˆ°æ›´å¤šçš„ä¿¡æ¯ã€‚

## å®Œå…¨å…¬å¹³è°ƒåº¦ç®—æ³•

ä»Šå¤©ä»‹ç»çš„æ˜¯åœ¨å†…æ ¸2.6.2å·¦å³æ‰è¢«æ­£å¼åˆå¹¶çš„ä¸€ä¸ªç®—æ³•ï¼ŒCFS\( completely fair scheduler \) ï¼Œå®ƒçš„æ€æƒ³éå¸¸çš„ç®€å•ï¼Œå¯èƒ½å…·ä½“çš„å®ç°ä¸Šå·²ç»æ›´æ–°æ¢ä»£å¾ˆä¹…äº†ï¼Œä½†æ˜¯ä¸ç®¡å¤šä¹ˆå¤æ‚ï¼Œæ ¸å¿ƒçš„æ€æƒ³æ˜¯æ²¡æœ‰æ”¹å˜çš„ï¼Œæˆ‘ä»¬å¾—äº†è§£çš„å°±æ˜¯è®¾è®¡çš„æ€æƒ³ï¼Œå…·ä½“çš„å®ç°æ˜¯æ ¹æ®å®é™…çš„éœ€è¦åšæ”¹åŠ¨çš„ã€‚

### ç†æƒ³çš„CPU

å½“æ—¶ç¬¬ä¸€ä¸ªç‰ˆæœ¬çš„[è¡¥ä¸](https://lwn.net/Articles/230501/)ï¼Œä½œè€…å¯¹è¿™ä¸ªç®—æ³•çš„æ€æƒ³åšäº†ä¸€ä¸ªç®€å•çš„æ¦‚è¿°ï¼Œç„¶åç¬”è€…åœ¨å…¶æåˆ°çš„ä¸€ä¸ªä¸»é¡µä¸Šæ‰¾åˆ°äº†ç›¸å¯¹è¯¦ç»†ä¸€ç‚¹çš„[æ¦‚è¿°](http://people.redhat.com/mingo/cfs-scheduler/sched-design-CFS.txt)ã€‚

> ```text
> 80% of CFS's design can be summed up in a single sentence: CFS basically
> models an "ideal, precise multi-tasking CPU" on real hardware.
>
> "Ideal multi-tasking CPU" is a (non-existent  :-))  CPU that has 100%
> physical power and which can run each task at precise equal speed, in
> parallel, each at 1/nr_running speed. For example: if there are 2 tasks
> running then it runs each at 50% physical power - totally in parallel.
> ```

ä½œè€…æåˆ°äº†ï¼ŒCFS çš„è®¾è®¡å°±æ˜¯ä¸€å¥è¯ï¼ŒCFSæ¨¡æ‹Ÿäº†ä¸€ä¸ªç†æƒ³åŒ–å¤šä»»åŠ¡å¤„ç†å™¨ï¼Œä¸‹é¢æœ‰ç€è¯¦ç»†çš„è§£é‡Šï¼Œå°±æ˜¯è¯´å¦‚æœæœ‰ n ä¸ªè¿›ç¨‹ï¼Œé‚£ä¹ˆåœ¨å»¶è¿Ÿ delay ä¸‹ï¼Œå°±æ˜¯æ¯ä¸ªä»»åŠ¡è¿è¡Œ delay/n çš„æ—¶é—´ã€‚

è¿™ä¸ªè®¾è®¡ï¼Œå¤Ÿç®€å•äº†å§ã€‚ä¹Ÿå°±æ˜¯è¯´å†…æ ¸ä¸ä¼šåœ¨è°ƒåº¦ä¸Šæœ‰ä»»ä½•çš„åå·®ï¼Œæ˜¯å®Œå…¨å…¬å¹³çš„ã€‚

### ç›¸å¯¹çš„å…¬å¹³

äººç”Ÿå“ªæœ‰ç»å¯¹çš„å…¬å¹³å‘¢ï¼Œæ“ä½œç³»ç»Ÿä¹Ÿæ˜¯ä¸€æ ·çš„ï¼Œä¸ç„¶ä¹Ÿå°±ä¸ä¼šæœ‰ _**nice**_ è°ƒç”¨äº†ï¼Œç°åœ¨åœ¨è¿™æŠŠè¿™ä¸ªå…¬å¹³çš„å®è´¨è¯´æ¸…æ¥šï¼Œé¦–å…ˆï¼Œå…¬å¹³æŒ‡çš„æ˜¯ï¼Œè°ƒåº¦å™¨åœ¨é€‰æ‹©è¿›ç¨‹çš„æ—¶å€™ï¼Œ_**ä¸ä¼šå› ä¸ºä½ çš„ç‰¹æƒé«˜è€Œé€‰æ‹©ä½ ï¼Œè€Œä¼šå› ä¸ºä½ æ²¡æœ‰æ‰§è¡Œå®Œè‡ªå·±çš„æ—¶é—´è€Œé€‰æ‹©ä½ **_ã€‚è¿™å¥è¯ï¼Œå°±æ˜¯å…¬å¹³çš„æœ¬è´¨ã€‚

ä¸¾ä¸ªä¾‹å­ï¼Œä¸€ä¸ªè¿›ç¨‹niceå€¼ä¸º-20ï¼Œæœ€é«˜ç‰¹æƒçº§ï¼Œä½†æ˜¯å®ƒæ‰§è¡Œå®Œäº†è‡ªå·±åº”è¯¥æœ‰çš„æ—¶é—´ï¼Œè€Œæœ‰ä¸€ä¸ªniceå€¼ä¸º0çš„è¿›ç¨‹ç­‰å¾…IOè¢«å”¤é†’ï¼Œé‚£ä¹ˆå¯¹äº CFS æ¥è¯´ï¼Œå®ƒè¿˜æ˜¯ä¼šé€‰æ‹©åè€…ï¼Œè™½ç„¶è¯´ CFS å¹¶æ²¡æœ‰äº¤äº’æ€§è¿›ç¨‹çš„è¯†åˆ«ç®—æ³•ï¼Œä½†æ˜¯äº¤äº’æ€§è¿›ç¨‹æœ¬èº«å°±æœ‰ä¸€ä¸ªæ˜¾è‘—çš„ç‰¹ç‚¹ï¼Œé‚£å°±æ˜¯ç»å¸¸ç­‰å¾…IO ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸ªè¿›ç¨‹æ ¹æ®è‡ªå·±çš„ nice å€¼ï¼Œä¹Ÿæ˜¯æ ¹æ®è‡ªå·±çš„ç‰¹æƒçº§é«˜ä½ï¼Œä¼šå¾—åˆ°**ä¸åŒé•¿åº¦**çš„**æ—¶é—´ç‰‡**ï¼Œè°ƒåº¦å™¨**åœ¨ä¹çš„æ˜¯ä½ æ˜¯ä¸æ˜¯æ²¡æœ‰æ‰§è¡Œå®Œè‡ªå·±çš„æ—¶é—´ï¼Œå¦‚æœæ²¡æœ‰ï¼Œè€Œä¸”ä½ è¿˜æ˜¯æœ‰æœ€å¤šçš„å¯ä½¿ç”¨çš„æ—¶é—´ï¼Œé‚£ä¹ˆæˆ‘å°±é€‰æ‹©ä½ æ‰§è¡Œ**ã€‚

### weight weight weight

è°¨ä»¥æ­¤å°æ ‡é¢˜è‡´æ•¬ wuli å¤å¤ ğŸ˜€ã€‚ç†è§£ CFS çš„æœ¬è´¨ï¼Œæœ‰ä¸€ä¸ªå¾ˆå…³é”®çš„å­—æ®µå°±æ˜¯ **weight**ï¼Œæˆ‘ä»¬å°å­¦æ¥è§¦ ä¸€æ¬¡å‡½æ•° çš„æ—¶å€™è¡¨è¾¾å¼ä¸º

$$y = kx + b$$

å®é™…ä¸Šåœ¨å›½å¤–ï¼Œä¸€ç§å¸¸è§çš„å†™æ³•æ˜¯

$$y = wx + b$$

è¿™é‡Œçš„ $$w$$ å°±æ˜¯æŒ‡ä»£ weight $$b$$ æŒ‡ä»£ bias ï¼Œæ¯ä¸€ä¸ªè¿›ç¨‹ï¼ˆè°ƒåº¦å•å…ƒï¼‰ï¼Œéƒ½æœ‰ä¸€ä¸ª weight å­—æ®µï¼Œä»£è¡¨å½“å‰çš„è¿›ç¨‹çš„â€œ é‡é‡ â€ï¼Œéå¸¸çš„å½¢è±¡ã€‚nice å€¼å’Œ weight çš„è½¬æ¢å¦‚ä¸‹ã€‚

![nice-to-weight-convertion](../.gitbook/assets/image%20%2893%29.png)

ä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªè§„åˆ™ï¼è‚¯å®šæœ‰è¯»è€…å°±å¥½å¥‡äº†ï¼Œç°åœ¨ä»¥ nice 0 å’Œ nice 1 çš„ä¸¤ä¸ªè¿›ç¨‹ä¸ºä¾‹å­ã€‚

é‚£ä¹ˆ

$$sum = 1024 + 820 = 1844$$

åˆ™ $$1024/1844\approx0.555$$

å†è®¡ç®— $$820/1844 \approx 0.445$$

ç°åœ¨æˆ‘å‘Šè¯‰ä½ ï¼Œè¿™ä¸ªæ¯”ä¾‹å°±æ˜¯ä¿©è¿›ç¨‹å ç”¨ CPU çš„æ¯”ä¾‹

ä¸¤è€… $$1024/820 = 1.248$$

è€Œ $$1.248 / ï¼ˆ1.248+1ï¼‰\approx 0.55$$ $$1 / (1.248+1) \approx 0.45$$

å¦‚æœç°åœ¨çŸ¥é“ nice = 0 è€Œ weight = 1024ï¼Œåˆ™ nice = -1 çš„ weight

$$weight = 1024 * 1.248 = 1277.952$$

æ‰€ä»¥ weight çš„ä½œç”¨ä¿è¯äº†ä¸€ç‚¹ï¼Œé‚£å°±æ˜¯å½“ä»–ä»¬çš„æ•°å€¼ç›¸å·® 1 å®ƒä»¬å ç”¨CPUçš„æ—¶é—´ç›¸å·®å¤§æ¦‚æ˜¯ 10%ï¼Œè¿™å°±æ˜¯ weight å­˜åœ¨çš„ä½œç”¨ã€‚

ç°åœ¨è€ƒè™‘æˆ‘ä»¬æœ‰ä¸€ä¸ªè¿è¡Œçš„é˜Ÿåˆ—ï¼Œæˆ‘ä»¬ç”¨ä¸€ä¸ªå­—æ®µæ¥è®°å½•å½“å‰é˜Ÿåˆ—æ‰€æœ‰è¿›ç¨‹çš„æ€»é‡ï¼Œæ¯å½“æœ‰æ–°çš„è¿›ç¨‹è¿›å…¥æˆ–è€…å‡ºåˆ—ï¼Œæˆ‘ä»¬å°±æ›´æ–°å®ƒï¼Œå‡è®¾è¿™ä¸ªå­—æ®µä¸º _**total\_weight**_

è€Œå¦‚ä»Šæˆ‘ä»¬é€‰æ‹©äº†ä¸€ä¸ªè¿›ç¨‹ $$t$$ æ¥æ‰§è¡Œï¼Œé‚£ä¹ˆå‡è®¾æˆ‘ä»¬å¯æ‰¿å—çš„å»¶è¿Ÿæ˜¯ 100ms

ä¹Ÿå°±æ˜¯è¯´ 100mså†… æˆ‘ä»¬å°±å¾—æŠŠæ‰€æœ‰çš„è¿›ç¨‹è°ƒåº¦ä¸€æ¬¡ï¼Œæ¥ä¿è¯ç”¨æˆ·çš„å¯ä½¿ç”¨æ€§ï¼Œé‚£ä¹ˆä½ è§‰å¾—è¿™ä¸ªè¿›ç¨‹åº”è¯¥æ‰§è¡Œå¤šé•¿æ—¶é—´å‘¢ï¼Ÿ

$$
time\_slice = \frac{t~->weight}{total\_weight} * 100~ms
$$

è¿™æ ·ï¼Œä¸Šé¢çš„ nice å’Œ weight çš„è½¬æ¢çš„ä½œç”¨æ˜¯ä¸æ˜¯å°±è§£é‡Šå®Œäº†ï¼Œè™½ç„¶ CFS åœ¨é€‰æ‹©è¿›ç¨‹ä¸Šæ˜¯å…¬å¹³çš„ï¼Œä½†æ˜¯æ¯ä¸ªè¿›ç¨‹èƒ½æ‰§è¡Œçš„æ—¶é—´æ˜¯ä¸å…¬å¹³çš„ï¼Œè¿™ç§ä¸å…¬å¹³æ˜¯ç”¨ weight æ¥ä»£è¡¨ï¼Œä¸€ä¸ªè¿›ç¨‹çš„â€œé‡é‡â€ï¼Œä»£è¡¨çš„æ˜¯åœ¨ä¸€æ®µæ—¶é—´å†…ï¼Œ**å®ƒçš„CPUä½¿ç”¨å æ¯”**ã€‚

çœ‹çœ‹å†…æ ¸ä»£ç çš„æ³¨é‡Š

```c
/*
 * Nice levels are multiplicative, with a gentle 10% change for every
 * nice level changed. I.e. when a CPU-bound task goes from nice 0 to
 * nice 1, it will get ~10% less CPU time than another CPU-bound task
 * that remained on nice 0.
 *
 * The "10% effect" is relative and cumulative: from _any_ nice level,
 * if you go up 1 level, it's -10% CPU usage, if you go down 1 level
 * it's +10% CPU usage. (to achieve that we use a multiplier of 1.25.
 * If a task goes up by ~10% and another task goes down by ~10% then
 * the relative distance between them is ~25%.)
 */
 static const int prio_to_weight[40] = {
 /* -20 */     88761,     71755,     56483,     46273,     36291,
 /* -15 */     29154,     23254,     18705,     14949,     11916,
 /* -10 */      9548,      7620,      6100,      4904,      3906,
 /*  -5 */      3121,      2501,      1991,      1586,      1277,
 /*   0 */      1024,       820,       655,       526,       423,
 /*   5 */       335,       272,       215,       172,       137,
 /*  10 */       110,        87,        70,        56,        45,
 /*  15 */        36,        29,        23,        18,        15,
};
```

### å†…æ ¸çš„è„‰æ

emï¼Œè‚¯å®šæœ‰è¯»è€…å¥½å¥‡ï¼Œæ‰§è¡Œçš„æ—¶é—´æ˜¯æ€ä¹ˆè®°å½•çš„å‘¢ï¼ŒåµŒå…¥å¼çš„åŒå­¦è‚¯å®šæ˜¯ä¸ä¼šä¸çŸ¥é“æ—¶é—´è„‰å†²è¿™ä¸ªæ¦‚å¿µï¼Œç®€å•çš„è¯´ï¼Œå†…æ ¸æ¯ä¸€æ®µå›ºå®šæ—¶é—´å°±æœ‰ä¸€æ¬¡æ—¶é—´ä¸­æ–­ï¼Œæˆ‘ä»¬ä¹Ÿç§°ä¹‹ä¸ºè„‰æï¼Œé‚£ä¹ˆæ¯ä¸€æ¬¡æ—¶é—´ä¸­æ–­ï¼Œæˆ‘ä»¬å°±åœ¨å½“å‰è¿›ç¨‹çš„è®°å½•ä¸‹åŠ ä¸€æ®µæ—¶é—´ï¼Œå¦‚æœå‘ç°å®ƒä¸€æ—¦è¶…è¿‡äº†å®ƒæ‰€èƒ½æ‰§è¡Œçš„æ—¶é—´ï¼Œæˆ‘ä»¬å°±ç»™è¿›ç¨‹åšä¸€ä¸ªæ ‡è®°ï¼Œå®ƒçš„æ—¶é—´åˆ°äº†ï¼Œç„¶åçœŸæ­£è¢« scheduleï¼ˆï¼‰ å‡½æ•°åˆ‡æ¢çš„æ—¶å€™ï¼Œæˆ‘ä»¬æŠŠå®ƒå½“å‰å¤šå‡ºæ¥çš„æ—¶é—´ä¹Ÿä»å®ƒä¸‹ä¸€æ¬¡æ‰£ï¼Œå…·ä½“æ€ä¹ˆå®ç°ç­‰ä¸‹å°±æ˜ç™½äº†ï¼Œæ€»ä¹‹è¿™å°±æ˜¯è®¾è®¡çš„æ€æƒ³ã€‚

### Fair Clock

æˆ‘ä¸€ç›´åœ¨çº ç»“ï¼Œæ˜¯ä»¥æœ€æ–°çš„ vruntime æ¥é˜è¿°ï¼Œè¿˜æ˜¯æœ€åˆçš„ Fair Clock æ¥é˜è¿°è¿™ä¸ªç®—æ³•ï¼Œæ€æ¥æƒ³å»ï¼Œæˆ‘å°±æŠŠ vruntime ç›¸å…³çš„åšå®¢æ”¾ä¸Šæ¥ï¼Œç„¶åæˆ‘è‡ªå·±ç”¨æœ€åˆçš„è®¾è®¡æ¥é˜è¿°å°±OK

å†…æ ¸æ˜¯ç”¨ **rq ï¼ˆRun Queueï¼‰**ç»´æŠ¤å½“å‰å¯è¿è¡Œçš„è¿›ç¨‹ï¼Œä¸Šé¢çš„è¿›ç¨‹æŒ‰ä¸€å®šçš„è§„åˆ™æ¥æ’åˆ—ï¼Œä»¥å½“å‰æ‰€è¯´çš„ CFS RQï¼Œå°±æ˜¯ä»¥ä¸€ä¸ª Fair Key çš„å€¼æ¥æ’åˆ—ï¼Œè¿™ä¸ªå€¼è®°å½•æ˜¯æœ€åä¸€æ¬¡è¢«è°ƒç¦»å‡º CPU çš„æ—¶å€™ Fair Clockçš„å€¼ã€‚

Fair Clockï¼Œ è®°å½•çš„æ˜¯ä½¿ç”¨ CPU çš„æ—¶é—´æ€»å’Œï¼Œä»¥çº³ç§’ä¸ºå•ä½ï¼Œä¹Ÿæ˜¯è¯´æœ€åˆçš„æ—¶å€™æ˜¯ 0ï¼Œç„¶åæ¯ä¸€æ¬¡æ—¶é—´ä¸­æ–­ï¼ˆè„‰æï¼‰ï¼Œæˆ‘ä»¬å°±æ›´æ–°å®ƒï¼Œä¸ä»…å¦‚æ­¤ï¼Œæ¯å½“æœ‰è¿›ç¨‹å…¥åˆ—æˆ–è€…å‡ºåˆ—ï¼Œæˆ‘ä»¬å°±æ›´æ–°è¿™ä¸ªå€¼ï¼Œå…¶å®å®ƒå°±æ˜¯ _**rq**_ çš„æ—¶é—´çº¿ï¼Œä½†æ˜¯å®ƒå±è”½äº†æ—¶é’Ÿï¼Œåªå…³å¿ƒè‡ªå·±è¿è¡Œäº†å¤šé•¿æ—¶é—´ã€‚

ç°åœ¨è¿˜è¦è°ˆè°ˆæ‰€æœ‰è¿›ç¨‹éƒ½æœ‰ä¸€ä¸ª Fair Keyï¼Œå®ƒçš„å€¼å°±æ˜¯ä¸Šæ¬¡æ‰§è¡Œå®ƒçš„ Fair Clock çš„å€¼ï¼Œå®é™…ä¸Šæ˜¯ä¸æ˜¯å°±æ˜¯å¯ä»¥ç®€å•ç†è§£ä¸ºï¼Œä¸Šæ¬¡æ‰§è¡Œè¿™ä¸ªè¿›ç¨‹çš„æ—¶é—´ã€‚æ³¨æ„ï¼Œè®°å½•çš„æ—¶é—´ä¸€å®šæ˜¯æœ€åè¿›ç¨‹è¢«åˆ‡å‡º CPU çš„æ—¶å€™ã€‚

ä¸ºäº†è¡¨è¿°æ–¹ä¾¿ï¼Œä¹‹åæˆ‘è¯´çš„æ—¶é—´ï¼Œå‡æŒ‡ä»£ Fair Clock çš„å€¼ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸€æ®µæ—¶é—´é—´éš”ï¼Œæˆ‘å°±æ›´æ–° _**rq**_ çš„ Fair Clockï¼ˆæ—¶é—´çº¿ï¼‰ï¼ŒåŒæ—¶ï¼Œå½“å‰CPUæ­£åœ¨æ‰§è¡Œçš„è¿›ç¨‹çš„ Fair Key ä¹Ÿæ›´æ–°ä¸ºè¿™ä¸ªå€¼ï¼Œæœ€åå½“è¿›ç¨‹å¤±å»äº†CPUï¼Œæˆ‘ä»¬ä¹Ÿæ›´æ–° Fair Keyï¼Œä»£è¡¨çš„æ˜¯**è¿›ç¨‹å¤±å»CPUèµ„æºçš„æœ€åæ—¶åˆ»**ã€‚

è€Œæˆ‘ä»¬å¦‚ä½•é€‰æ‹©ï¼Œæ–°çš„è¿›ç¨‹å‘¢ï¼Ÿ é‚£å°±æ˜¯é€‰æ‹© Fair Key æœ€å°çš„ä¸€ä¸ªè¿›ç¨‹ï¼Œæ˜¯ä¸æ˜¯å¾ˆå®¹æ˜“æƒ³åˆ°ï¼Œä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬é€‰æ‹©çš„æ˜¯æœ€ä¹…æ²¡æœ‰è¿è¡Œçš„ä¸€ä¸ªè¿›ç¨‹ï¼Œç†æ‰€å½“ç„¶è½®åˆ°å®ƒäº†ã€‚

é‚£ä¹ˆè¯»è€…å¯èƒ½ä¼šå¥½å¥‡ï¼Œä¸ºä»€ä¹ˆå‰é¢è¦åŠ ä¸€ä¸ª Fair ä¿®é¥°å®ƒå‘¢ï¼Œå®ƒä¸å°±æ˜¯ä¸€ä¸ªæ—¶é—´çº¿å—ï¼Œè¿™ä¸ªå­—æ®µå­˜åœ¨çš„æ„ä¹‰å°±æ˜¯å½“ä¸€ä¸ªå…¬å¹³çš„æ—¶é’Ÿï¼Œæ‰€ä»¥å¿…ç„¶æœ‰å®ƒä¸åŒçš„åœ°æ–¹ã€‚ç¨åæˆ‘ä»¬å°±ä¼šæ­æ™“ï¼Œé€šè¿‡å‰é¢å‡ èŠ‚çš„å™è¿°ï¼Œæˆ‘ä»¬çŸ¥é“ï¼Œä¸åŒä¼˜å…ˆçº§çš„è¿›ç¨‹èƒ½è·å¾—çš„æ—¶é—´ç‰‡é•¿åº¦æ˜¯ä¸åŒçš„ï¼Œå…·ä½“æœ‰å¤šå°‘å¾—å–å†³äºå®ƒçš„ weight ä»¥åŠ ç³»ç»Ÿæ‰€éœ€æ±‚çš„å»¶è¿Ÿï¼Œè¿˜æœ‰å½“å‰æ‰€æœ‰è¿›ç¨‹çš„ weight ä¹‹å’Œã€‚

é‚£ä¹ˆï¼ŒFair Clock æ˜¯æ€ä¹ˆå¢é•¿çš„ï¼Ÿå‰é¢æˆ‘ä»¬è¯´æ¯ä¸ªä¸€æ®µæ—¶é—´ deltaï¼Œæˆ‘ä»¬å°±æ›´æ–°å®ƒï¼Œä½†æ˜¯ Fair Clock å®é™…ä¸Šä¸æ˜¯ä¸€ä¸€å¯¹åº”ã€‚

$$
Fair\_Clock ~+= ~ \frac{1024}{t->\_weight} * delta
$$

ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯è¿‡ä¸€æ®µæ—¶é—´ï¼ŒFair Clock å…¶å®ä¼šæ¯”å®é™…çš„æ—¶é—´å¢é•¿çš„æ…¢ä¸€ç‚¹ï¼Œè¿™é‡ŒåŒæ—¶æ­ç¤ºäº†éå¸¸é‡è¦ä¸€ç‚¹ï¼Œ **ä¸åŒç‰¹æƒçº§çš„è¿›ç¨‹ï¼Œæ‰§è¡Œç›¸åŒçš„æ—¶é—´ï¼Œå¯¹ Fair Clock çš„å¢é•¿æ˜¯ä¸ä¸€æ ·çš„**ï¼æŒ‰ç…§å¸¸ç†æƒ³è±¡ï¼Œç‰¹æƒé«˜ï¼Œç†æ‰€åº”å½“å¯¹ Fair Clock ä½œç”¨å°ï¼Œå› ä¸º CFS é€‰æ‹©çš„æ˜¯æœ€ä¹…ä¹‹å‰è·å¾—CPUçš„è¿›ç¨‹ï¼Œå¦‚æ­¤å°±å¯ä»¥ä¿è¯ç‰¹æƒçº§é«˜çš„è¿›ç¨‹å¯ä»¥åœ¨é˜Ÿåˆ—çš„å‰æ–¹ï¼Œå½“ç„¶äº†ï¼Œ**å½“å®ƒä»¬éƒ½æ‰§è¡Œäº†è‡ªå·±çš„é‚£éƒ¨åˆ†æ—¶é—´ï¼Œå’Œä¸‹é¢çš„å…¬å¼è”ä¾‹ï¼Œå¯¹ Fair Clock å¢é•¿å°±æ˜¯ç›¸åŒçš„**ã€‚

$$
time\_slice = \frac{t~->weight}{total\_weight} * 100~ms
$$

$$
Fair\_Clock ~+= ~ \frac{1024}{total\_weight} *latency
$$

æ€»ç»“ä¸€ä¸‹ï¼Œ Fair Clock æ˜¯ä¸€ä¸ªå…¬å¹³çš„æ—¶é’Ÿï¼Œç›®çš„è®°å½•è¿›ç¨‹ç¦»å¼€ CPU çš„ä¸€ä¸ªâ€œæ—¶é—´â€ï¼ŒåŒæ—¶åˆæ ¹æ® nice çš„ä¸åŒï¼Œåšäº†ä¸ä¸€æ ·çš„å¤„ç†ï¼Œç»“æœå°±æ˜¯é«˜ç‰¹æƒçš„è¿›ç¨‹åœ¨ç›¸åŒçš„æ—¶é—´ä¸‹å¯¹å…¶ä½œç”¨å°ï¼Œä¹Ÿå°±æ˜¯ä¸ºäº†é«˜ç‰¹æƒçš„è¿›ç¨‹èƒ½å†æ¬¡é¡ºåˆ©è·å–å±äºå®ƒçš„é‚£ä»½æ—¶é—´ï¼Œè¯•æƒ³ä¸€ä¸‹ï¼Œå¦‚æœä½œç”¨æ˜¯ä¸€æ ·çš„ï¼Œé‚£ä¹ˆé«˜ç‰¹æƒçš„è¿›ç¨‹ï¼ˆå…ˆï¼‰å’Œæ™®é€šè¿›ç¨‹ï¼ˆåï¼‰æ‰§è¡Œäº†ç›¸åŒçš„æ—¶é—´ï¼Œç»“æœå› ä¸º Fair Key çš„å¢å¤§ï¼Œåˆ°äº†é˜Ÿåˆ—çš„åé¢ï¼Œè€Œæˆ‘æœ¬æ¥åº”è¯¥æ‹¥æœ‰æ›´å¤šçš„æ—¶é—´ï¼Œä½†æ˜¯å´å› ä¸ºâ€å…¬å¹³å¯¹å¾…â€œï¼Œå¯¼è‡´äº†ä¸å…¬å¹³ã€‚

### è¿›ç¨‹çˆ±ç¡è§‰ - wait\_runtime

åˆšæ‰æˆ‘ä»¬è¯´äº†ï¼Œå½“ä¸€ä¸ªè¿›ç¨‹æ¶ˆè€—å®Œäº†è‡ªå·±çš„æ—¶é—´ï¼Œé‚£ä¹ˆå®ƒè¢«åˆ‡å‡ºä¹‹å‰ï¼Œæˆ‘ä»¬ä¼šç»™å®ƒçš„ Fair Key èµ‹å€¼ä¸ºå½“å‰çš„ Fair Clockï¼Œä»£è¡¨å®ƒæ­¤æ—¶æœ€åä¸€æ¬¡è¢«è°ƒåº¦çš„æ—¶é—´ã€‚è€ƒè™‘ä¸€ä¸ªæƒ…å†µï¼Œä¸€ä¸ªè¿›ç¨‹å†å¼€æœºå°±è‡ªåŠ¨è¿è¡Œï¼Œç„¶åé©¬ä¸Šç¡çœ ï¼Œæ¥ç€ä¸€å°æ—¶ä¹‹åå®ƒæ¥æ‰§è¡Œã€‚

å¿˜äº†è¯´æ˜ä¸€ç‚¹ï¼Œç¡çœ çš„æ—¶å€™ï¼Œå¿…ç„¶ä¼šå¯¼è‡´è¿›ç¨‹ç¦»å¼€ _**rq**_ï¼Œå› ä¸º _**rq**_ ç»´æŠ¤çš„é˜Ÿåˆ—é‡Œå‚¨å­˜éƒ½æ˜¯å·²ç»å°±ç»ªçš„è¿›ç¨‹ï¼Œé‚£ä¹ˆ CFS å°±ä¼šè®°å½•å®ƒå‡ºåˆ—æ—¶çš„ Fair Clock èµ‹å€¼å…¶ Fair Keyï¼Œå¹¶ä¸”å‘¢ï¼Œå®ƒçŸ¥é“è¿›ç¨‹è¦å»ç¡çœ ï¼Œå› ä¸ºä¼ å…¥çš„å‚æ•°ä¼šæ ‡æ˜ï¼Œæ‰€ä»¥å®ƒè¿˜è®°å½•äº† **sleep\_start\_fair** è¿™ä¸ªå€¼ï¼Œæ„å‘³ç€ç¡çœ å¼€å§‹çš„ Fair Clockçš„å€¼ã€‚

é‚£ä¹ˆï¼Œè¿›ç¨‹å†æ¬¡å”¤é†’ï¼Œä¸€ä¸ªå°æ—¶æœ€åï¼Œé‡æ–°å…¥åˆ—ï¼Œå¯æƒ³è€ŒçŸ¥ï¼Œå¿…ç„¶æ˜¯åœ¨é˜Ÿåˆ—ç¬¬ä¸€ä½ï¼Œç»è¿‡ä¸€æ¬¡è°ƒåº¦åï¼Œç«‹å³å¾—åˆ°äº† CPU çš„ä½¿ç”¨æƒï¼Œå¦‚æœç…§ç€å‰å‡ èŠ‚æ‰€è¯´ï¼Œé‚£ä¹ˆå®ƒä¼šè·å¾—ä¸€æ®µæ—¶é—´ï¼Œæ ¹æ®è‡ªå·±çš„ weight ï¼Œæ‰§è¡Œå®Œå Fair Key ç«‹å³æ›´æ–°ä¸º å½“å‰çš„ Fair Clockã€‚

æœ‰é—®é¢˜å—ï¼Ÿä»”ç»†æƒ³æƒ³ï¼Œå®ƒçš„ Fair Key åœ¨ä¸€æ®µéå¸¸çŸ­çš„æ—¶é—´å†…ï¼ˆè¿›ç¨‹å ç”¨CPUä¹‹åçš„æœ€è¿‘ä¸€æ¬¡çš„æ›´æ–°ï¼‰ï¼Œç«‹å³å¢é•¿äº†å¥½å‡ å€ï¼Œå› ä¸ºå®ƒçš„ Fair Key åœ¨æ˜¯ä¸€å°æ—¶ä»¥å‰çš„ Fair Clockï¼Œç»“æœæ‰§è¡Œäº†ä¸€æ®µæ—¶é—´ä»¥åï¼Œå®ƒåˆè·Ÿå…¶ä»–çš„è¿›ç¨‹å¹³èµ·å¹³åäº†ï¼Œè¿™æœ‰å¤±å…¬å…ã€‚

æ‰€ä»¥æˆ‘ä»¬æœ‰å“ªäº›æ‰‹æ®µï¼Ÿ æŠŠå®ƒçš„ Fair Key å‡æ‰ä¸€éƒ¨åˆ†ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼ŒFair Key ä¸åœ¨æ˜¯ä¸ Fair Clock ä¼ªåŒæ­¥äº†ï¼Œå‰ªæ‰çš„ä¸€éƒ¨åˆ†æˆ‘ä»¬ç§°ä¸º wait\_runtimeï¼Œå¯ä»¥ç®€å•çš„ç†è§£ä¸ºç¡çœ çš„æ—¶é—´ï¼Œå…¶å®å¹¶ä¸æ˜¯ï¼Œä¸ºä»€ä¹ˆå‘¢ï¼Œå¦‚æœè¿›ç¨‹ç¡çœ äº†ä¸€å°æ—¶ï¼Œæˆ‘ä»¬è¿˜è®©å®ƒ Fair Key è½å Fair Clock ä¸€ä¸ªå°æ—¶ä¹ˆï¼Ÿè¿™æ ·è¿™ä¸ªè¿›ç¨‹æ°¸è¿œéƒ½ä¼šæ˜¯è¢«æ‰§è¡Œçš„ä¸€ä¸ªï¼Œå°±æ²¡æœ‰å…¬å¹³è¿™ä¸€è¯´äº†ã€‚

```text
"wait_runtime" is the amount of time the task should now run on 
the CPU for it to become completely fair and balanced.

small detail: on 'ideal' hardware, the p->wait_runtime value would
always be zero - no task would ever get 'out of balance' from the
'ideal' share of CPU time.
```

è¿™ä¸ªå€¼è®°å½•çš„æ˜¯ä¸€ä¸ªå¹³è¡¡å€¼ï¼Œå¯ä»¥æ˜¯æ­£çš„ä¹Ÿå¯ä»¥æ˜¯è´Ÿçš„ï¼Œå®ƒä»£è¡¨äº†å½“å‰è¿›ç¨‹ä¸€ä¸ªæŒ‡æ ‡ï¼Œå°±æ˜¯èƒ½ä½¿å®ƒèƒ½å¾—åˆ°è‡ªå·±é‚£ä»½èµ„æºçš„ä¸€ä¸ªåº¦é‡ï¼Œå¦‚æœæ˜¯æ­£çš„ï¼Œæ„å‘³ç€å®ƒåº”è¯¥å¾—åˆ°æ›´å¤šï¼Œå¦‚æœæ˜¯è´Ÿçš„ï¼Œæ„å‘³ç€å®ƒå·²ç»å¾—åˆ°äº†è¶…è¿‡äº†è‡ªå·±åº”è¯¥è·å¾—ã€‚

$$
Fair\_Key = Fair\_Clock - wait\_runtime
$$

å¦‚æœå®ƒæ˜¯è´Ÿçš„ï¼Œé‚£ä¹ˆå®ƒåœ¨æ›´æ–°ä¹‹åå°±ä¼šæ¯” Fair Clock è¿˜è¦å¤§ï¼Œå¦‚æœæ˜¯æ­£çš„ï¼Œæ„å‘³ç€å®ƒä¼šæ¯”å®ƒæ›´å°ã€‚è®¾è®¡çš„äººä¹Ÿç•™ä¸‹äº†æ³¨é‡Šï¼Œåœ¨ç†æƒ³çš„ç¯å¢ƒä¸‹ï¼Œæ¯ä¸ªè¿›ç¨‹æ‰§è¡Œå®Œè‡ªå·±çš„æ—¶é—´ï¼Œå°±åˆ‡æ¢ä¸‹ä¸€ä¸ªè¿›ç¨‹ï¼Œè¿™æ ·åœ¨ä¸€æ®µæ—¶é—´å†…ï¼Œå®ƒä»¬çš„ Fair \_Key ä¸€å®šç›¸åŒï¼ˆæœ‰æ—¶ä¸åŒï¼Œä½†æ˜¯å¤§è‡´ä¸Šä¸€å®šæ˜¯ä¸€æ ·çš„ï¼‰è€Œä¸” wait\_runtime ä¸º 0ï¼Œå› ä¸ºæ²¡æœ‰ä¸å…¬å¹³å‡ºç°ï¼Œä½†æ˜¯ä»¥ä¸‹å‡ ç‚¹å¯¼è‡´äº†ä¸å…¬å¹³ã€‚

* è¿›ç¨‹å”¤é†’å’Œç¡çœ ï¼Œå¯¼è‡´äº† wait\_runtime ä¸ä¸º 0
* æ—¶é—´ç‰‡åˆ†å‰²ç²’åº¦ä¸ä¸€å®šæ˜¯èµ‹äºˆå®ƒçš„æ—¶é—´çš„å…¬çº¦æ•°ï¼Œé‚£ä¹ˆè¿›ç¨‹å°±ä¼šæ‰§è¡Œæ¯”é¢„è®¡çš„æ—¶é—´å¤šäº†ç‚¹

å¯èƒ½è¿˜æœ‰å…¶ä»–åŸå› ï¼Œè¿˜æ²¡æƒ³åˆ°ï¼Œå…¶å®å°±æ˜¯å› ä¸ºä¸æ˜¯ç†æƒ³çš„æƒ…å†µï¼Œæ‰€ä»¥æ€»æ˜¯æœ‰ä¸å…¬å¹³çš„æƒ…å†µå‡ºç°ï¼Œæ‰€ä»¥éœ€è¦è¿™ä¸ªæŒ‡æ ‡ï¼Œè®© CFS è°ƒæ•´ã€‚

```text
CFS's task picking logic is based on this p->wait_runtime value and it
is thus very simple: it always tries to run the task with the largest
p->wait_runtime value.
```

Fair Clock åœ¨ä¸€å®šæ—¶é—´å†…å…¶å®æ²¡æœ‰åŒºåˆ«ï¼Œå› ä¸ºæ¯ä¸ªè¿›ç¨‹è¢«è°ƒåº¦å°±ä¼šè¢«æ›´æ–°ä¸€æ¬¡ï¼Œåªè¦æ—¶é—´åˆ‡å‰²çš„ä¸æ˜¯å¤ªä¹…ï¼Œæˆ‘ä»¬å°±å¯ä»¥è®¤ä¸º Fair Clock æ˜¯å‡ ä¹ç›¸åŒçš„ï¼Œæ­£æ˜¯å› ä¸ºä¸Šé¢è¯´çš„çŠ¶å†µå‡ºç°ï¼Œå¯¼è‡´äº† wait \_runtime ä¸ä¸º0ï¼Œé‚£ä¹ˆ Fair Key ä¹Ÿå°±ä¸å’Œ Fair Clock åŒæ­¥äº†ã€‚

æ‰€ä»¥ï¼Œè®¾è®¡çš„äººå°±è®¤ä¸ºè¿™ä¸ªç®—æ³•æœ¬è´¨å°±æ˜¯æŒ‘é€‰æœ€å¤§çš„ wait\_runtime çš„ä¸€ä¸ªè¿›ç¨‹ã€‚ç°åœ¨å›åˆ°åˆšæ‰é‚£ä¸ªæƒ…å†µï¼Œå½“è¿›ç¨‹ä¸€ä¸ªè¿›ç¨‹å…¥åˆ—çš„æ—¶å€™ï¼Œå¦‚æœä¼ å…¥å‚æ•°è¡¨æ˜ï¼Œå®ƒæ˜¯ç”± **ç¡çœ â†’å°±ç»ª** çŠ¶æ€ï¼Œé‚£ä¹ˆæˆ‘å°±å¾—è°ƒæ•´å®ƒçš„ wait\_runtime äº†ã€‚

é¦–å…ˆï¼Œè·å–å®ƒçš„ç¡çœ æ—¶é—´ $$delta = Fair\_Clock - sleep\_start\_fair$$ ç„¶åè®¡ç®—å®ƒçš„åº”è¯¥å¾—åˆ°å¤šå°‘è¡¥å¿

$$
wait\_runtime = \frac{delta*~t->weight}{1024}
$$

ä¹Ÿå°±æ˜¯è¯´ï¼Œå½“è¿›ç¨‹çš„**ä¼˜å…ˆçº§**è¶Šé«˜ï¼Œå¾—åˆ°çš„è¡¥å¿ä¹Ÿå°±è¶Šå¤šï¼Œå½“ç„¶è¿™ä¸ªæ˜¯æœ‰_**ä¸Šé™**_çš„ï¼Œå°±æ˜¯ä¸ºäº†é˜²æ­¢å­˜åœ¨ä¸€ä¸ªç¡çœ ä¸€ä¸ªå°æ—¶ï¼Œç„¶åæ‰§è¡Œä¸€å°æ—¶ä¸ºäº†ç ´åç³»ç»Ÿè°ƒåº¦è¿™æ ·çš„æµæ°“ç¨‹åºï¼Œæ¯”å¦‚è¿™ä¸ªä¸Šé™æ˜¯ä¸‰ä¸ªæ—¶é—´ç‰‡çš„é•¿åº¦è½¬åŒ–çš„å€¼ï¼Œå·²ç»å¾ˆé•¿äº†ï¼Œä¸ºä»€ä¹ˆï¼Ÿä¸€èˆ¬å­˜åœ¨è¿™ç§é•¿æ—¶é—´ç¡çœ çš„ç¨‹åºï¼Œæœ‰ä¸ªç‰¹ç‚¹ï¼Œä¸€å®šæ˜¯å¤„ç†å®Œåˆç»§ç»­ç¡çœ çš„ï¼Œå½“ç„¶ï¼Œä¸å¯ä¸€æ¦‚è€Œè®ºï¼Œæ‰€ä»¥è¿™ä¸ªå€¼åº”è¯¥ç”±ç³»ç»Ÿç®¡ç†å‘˜å†³å®šã€‚

æ€»ä¹‹ï¼Œå¯¹äºç¡çœ çš„è¿›ç¨‹ï¼ŒCFS å¯¹å…¶æ˜¯æœ‰ä¸€å®šçš„**å±æ€§åŠ æˆ**çš„ï¼Œä¸ºäº†å¹³è¡¡å®ƒä¹‹å‰æ”¶åˆ°çš„ä¸å…¬å¹³å¯¹å¾…ï¼Œä¸è¿‡è¿™ç§è°ƒæ•´æ˜¯æœ‰é™çš„ï¼Œå› ä¸ºä¸æ˜¯è°ƒåº¦å™¨æœ¬èº«çš„åŸå› å¯¼è‡´çš„å»¶è¿Ÿã€‚

ç»è¿‡å¦‚ä¸Šçš„åˆ†æï¼Œæˆ‘ä»¬å‘ç° CFS è™½ç„¶æ²¡æœ‰é’ˆå¯¹ interactive çš„è¿›ç¨‹ä¼˜åŒ–ï¼Œä½†æ˜¯æœ¬èº«è¿™ç±»è¿›ç¨‹æ˜¯ IO-bound æ‰€ä»¥ï¼Œå®ƒåœ¨ CFS çš„ååº”ä¸€å®šæ˜¯å¾ˆå¿«çš„ï¼Œè¿™ä¹Ÿä½¿å¾—æ¡Œé¢å“åº”çš„é€Ÿåº¦åŠ å¿«ï¼Œä½†æ˜¯å…¶ä»–çš„è¿›ç¨‹åŒæ ·ä¹Ÿæ²¡æœ‰è½ä¸‹ï¼Œæ‰€ä»¥ CFS è®¾è®¡ç®€å•ï¼Œä½†æ˜¯éå¸¸çš„é€‚åˆå†…æ ¸è°ƒåº¦çš„éœ€æ±‚ã€‚

### è¿›ç¨‹ä½•æ—¶è°ƒåº¦

åˆ°åº•ä»€ä¹ˆæ—¶å€™ä¸€ä¸ªè¿›ç¨‹æ‰éœ€è¦è¢«è°ƒåº¦ï¼Œè¿™å®é™…ä¸Šæ˜¯ä¸€ä¸ªæ ¸å¿ƒçš„é—®é¢˜ï¼Œç®€å•çš„å›ç­”å¯ä»¥è¯´æ˜¯æ—¶é—´ç‰‡æ¶ˆè€—å®Œäº†å°±åº”è¯¥è¢«è°ƒåº¦ï¼Œè¿™æ˜¯æ¯«æ— ç–‘é—®çš„ï¼Œä½†æ˜¯æ€»æœ‰è¿›ç¨‹é€‰æ‹©ä¸»åŠ¨é‡Šæ”¾ CPU çš„ä½¿ç”¨æƒï¼Œè½¬è€Œç¡çœ ï¼Œè€Œå½“å…¶å†è‹é†’çš„æ—¶å€™ï¼Œåº”è¯¥ä»€ä¹ˆæ—¶å€™æ‰è·å¾— CPU çš„ä½¿ç”¨æƒï¼Œè¿™æ˜¯ä¸€å¤§éš¾é¢˜ã€‚

CFS ç›´æ¥æ‘’å¼ƒäº†è¿™äº›æ¦‚å¿µï¼Œå®ƒåªè´Ÿè´£è®°è´¦ï¼Œè°æ­¤åˆ»æœ€éœ€è¦ CPUï¼Œå°±è®©è°ä½¿ç”¨ï¼Œå·§å¦™ä¹‹å¤„åœ¨äºï¼Œç»å¸¸æ€§ç¡çœ çš„è¿›ç¨‹åœ¨å®ƒçš„çœ¼ä¸­æ­£æ˜¯æœ€éœ€è¦ CPU çš„ã€‚

æ¯ä¸€æ¬¡æ—¶é—´ä¸­æ–­ï¼Œå†…æ ¸éƒ½ä¼šè°ƒç”¨è°ƒåº¦å™¨çš„ç›¸å…³å‡½æ•°ï¼Œæ¥åˆ¤æ–­å½“å‰çš„è¿›ç¨‹æ˜¯å¦éœ€è¦è¢«æ¢å‡ºï¼ŒåŸºäº 2.6.23 çš„ä»£ç ï¼Œå¯ä»¥ç†è§£ä¸ºå¦‚ä¸‹ã€‚

1. é¦–å…ˆï¼ŒæŠŠå½“å‰è¿›ç¨‹å‡ºåˆ—å¹¶å…¥åˆ—ï¼Œè¿™ä¸€æ­¥æ˜¯ä¸ºäº†æ›´æ–° Fair Clock/Key ç­‰ä¿¡æ¯
2. ç„¶ååˆ¤æ–­å½“å‰ Fair Key æœ€å°çš„æ˜¯å¦ä»ä¸ºå½“å‰è¿›ç¨‹ï¼Œå¦‚æœä¸æ˜¯ï¼Œåˆ™åšå¦‚ä¸‹åˆ¤æ–­ã€‚
3. å…ˆè®¡ç®—å€™é€‰è¿›ç¨‹å’Œå½“å‰è¿›ç¨‹çš„ Fair Key ä¹‹å·® $$delta$$ 
4. ç„¶åè®¡ç®—å½“å‰è¿›ç¨‹å·²ç»æ‰§è¡Œçš„æ—¶é—´ $$delta\_exe$$ 
5. å¦‚æœè¿›ç¨‹å·²ç»è¶…è¿‡äº†å½“å‰å½“å‰è¿›ç¨‹åº”è¯¥æ‰§è¡Œçš„æ—¶é—´ï¼Œé‚£ä¹ˆåˆ™å¯ä»¥æ¢å‡ºå½“å‰è¿›ç¨‹
6. å¦åˆ™ï¼Œå¦‚æœ $$delta$$ å°äºä¸€å®šçš„å€¼ï¼Œåˆ™ä¸ç”¨æ¢å‡ºã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼Œåªæœ‰å·®å€¼æ»¡è¶³äº†ä¸€å®šçš„éœ€æ±‚ï¼Œæ‰è®¤ä¸ºè¿›ç¨‹éœ€è¦è¢«è°ƒåº¦äº†ï¼Œæ˜¯æ—¶å€™ä»‹ç»ä¸€ä¸ªæ¦‚å¿µäº†ã€‚

#### Granularity - ç²’åº¦

è¿™ç¯‡æ–‡ç« ä¸€ç›´åœ¨é¿å…æ¶‰åŠæºä»£ç ï¼Œå“ˆå“ˆå“ˆï¼Œå› ä¸ºæºä»£ç å¤ªé«˜æ·±è«æµ‹äº†ï¼Œå¾ˆå¤šå€¼éƒ½æ˜¯é€šè¿‡æµ‹å‡ºæ¥çš„ï¼Œè¿™ä¹Ÿæ˜¯æœºå™¨å­¦ä¹ çš„æ€æƒ³ï¼Œå¾ˆå¤šæ—¶å€™æ²¡æœ‰ç»å¯¹çš„æœ€ä¼˜è§£ï¼Œéƒ½æ˜¯é€šè¿‡ä¸€æ­¥æ­¥å°è¯•å‡ºæ¥å¾—åˆ°å½“å‰çš„æœ€ä¼˜è§£ï¼Œæ‰€ä»¥æˆ‘ä»¬å¿…é¡»å¾—äº†è§£å…¶æ€æƒ³ï¼Œç„¶åè‡ªå·±å†æ¥æµ‹è¯•ã€‚

é¢—ç²’åº¦ï¼Œæè¿°çš„æ˜¯ä¸€ä¸ªè¿›ç¨‹æ‰§è¡Œçš„æ—¶é—´å•ä½ï¼Œå…¶å®å¾ˆå½¢è±¡ï¼Œé¢—ç²’åº¦æœ¬æ¥å°±æ˜¯ç”¨æ¥æè¿°åˆ†å‰²ç¨‹åº¦çš„ï¼Œå®ƒçš„å€¼è¶Šå°ï¼Œæ„å‘³ç€è¿›ç¨‹çš„ä¸€æ®µæ—¶é—´ç‰‡å°±è¶Šå°ã€‚å®ƒæ­£ç¡®çš„ç†è§£åº”è¯¥æ˜¯ï¼Œæè¿°ä¸€ä¸ªæœ€å°å•ä½çš„å€¼ï¼Œæˆ‘æ„Ÿè§‰æ˜¯è¿™æ · \(ï¿£â–½ï¿£\)"

> The CFS scheduler offers a single tunable: a "granularity" value which describes how quickly the scheduler will switch processes in order to maintain fairness. A low granularity gives more frequent switching; this setting translates to lower latency for interactive responses but can lower throughput slightly. Server systems may run better with a higher granularity value. --[cite\_here](https://lwn.net/Articles/230574/)

å½¢è±¡åœ°è¯´ï¼Œgranularity å°±æ˜¯æŒ‡ä¸€ä¸ªè¿›ç¨‹ä½¿ç”¨CPUä¹‹ååº”è¯¥æ‰§è¡Œçš„æ—¶é—´ï¼Œæˆ‘ä»¬ä¹‹é—´éƒ½æ˜¯ç”¨ slice æ¥è¡¨ç¤ºçš„ï¼Œå…¶å®æ˜¯ä¸€å›äº‹ã€‚æ¥çœ‹çœ‹ï¼Œå†…æ ¸ä»£ç å¦‚ä½•è®¡ç®— gran

```c
/*
 * Calculate the preemption granularity needed to schedule every
 * runnable task once per sysctl_sched_latency amount of time.
 * (down to a sensible low limit on granularity)
 *
 * For example, if there are 2 tasks running and latency is 10 msecs,
 * we switch tasks every 5 msecs. If we have 3 tasks running, we have
 * to switch tasks every 3.33 msecs to get a 10 msecs observed latency
 * for each task. We do finer and finer scheduling up to until we
 * reach the minimum granularity value.
 *
 * To achieve this we use the following dynamic-granularity rule:
 *
 *    gran = lat/nr - lat/nr/nr
 *
 * This comes out of the following equations:
 *
 *    kA1 + gran = kB1
 *    kB2 + gran = kA2
 *    kA2 = kA1
 *    kB2 = kB1 - d + d/nr
 *    lat = d * nr
 *
 * Where 'k' is key, 'A' is task A (waiting), 'B' is task B (running),
 * '1' is start of time, '2' is end of time, 'd' is delay between
 * 1 and 2 (during which task B was running), 'nr' is number of tasks
 * running, 'lat' is the the period of each task. ('lat' is the
 * sched_latency that we aim for.)
 */
static long
sched_granularity(struct cfs_rq *cfs_rq)
{
    unsigned int gran = sysctl_sched_latency;
    unsigned int nr = cfs_rq->nr_running;

    if (nr > 1) {
        gran = gran/nr - gran/nr/nr;
        gran = max(gran, sysctl_sched_min_granularity);
    }

    return gran;
}
```

ç®€å•çš„è¯´å‘¢ï¼Œå°±æ˜¯è¯´è¿™ä¸ªè¿›ç¨‹ï¼Œæˆ‘ç°åœ¨ç»™ä½ CPUä½¿ç”¨ï¼Œä½†æ˜¯ gran æ—¶é—´è¿‡å»ä¹‹åï¼Œä½ å°±å¾—å½’è¿˜äº†ï¼Œå› ä¸ºæˆ‘å¾—ä¿è¯ç³»ç»Ÿçš„å“åº”æ—¶é—´åœ¨ä¸€å®šçš„å»¶è¿Ÿå†…ã€‚

åˆšæ‰æˆ‘ä»¬æåˆ°çš„ $$delta$$ å¤§äºä¸€ä¸ªå€¼çš„è¯å°±å¾—æŠŠå½“å‰çš„è¿›ç¨‹æ¢å‡ºäº†ï¼Œè¿™ä¸ªå€¼ä¸å®ƒæœ‰å…³ï¼Œå‡è®¾è®¡ç®—å‡ºæ¥çš„å€¼ä¸º gran é‚£ä¹ˆæœ€ç»ˆè¿™ä¸ªå€¼æ˜¯

$$
niced\_granularity = \left\{ \begin{array}{ll}
\frac{gran~*~1024}{weight} & \textrm{if weight>=~1024}\\
& \\
\frac{gran~*~weight}{1024} & \textrm{if weight < 1024}\\
\end{array} \right.
$$

ä¹Ÿå°±æ˜¯è¯´å‘¢ï¼Œè¿™ä¸ªå€¼è¿˜å–å†³äºå½“å‰è¿›ç¨‹çš„ weightï¼Œå¾—åˆ°çš„ niced\_gran å¦‚æœä¸æ˜¯1024ï¼Œéƒ½æ˜¯æ¯”å…¶å°çš„ï¼Œ**è¿™é‡Œæˆ‘å¹¶æ²¡æœ‰ç†è§£å…¶åŸå› **ï¼ï¼æ³¨æ„ï¼Œè¿™é‡Œçš„ä»£ç éƒ½æ˜¯åŸºäº 2.6.23 çš„ï¼Œå¦‚æœæŸ¥çœ‹2.6.27 çš„ä»£ç ï¼Œå…¶å®å·²ç»æ²¡æœ‰è¿™ä¸ªåˆ¤æ–­äº†ï¼Œæˆ‘ä»¬éœ€è¦ç†è§£çš„æ˜¯ä¸€ç‚¹ï¼Œ**åªè¦ä¿©è€…ç›¸å·®çš„è·ç¦»è¿‡å¤§**ï¼Œæˆ‘ä»¬å°±å¾—é‡æ–°è°ƒåº¦äº†ã€‚

{% hint style="info" %}
é‡æ–°è°ƒåº¦å¹¶ä¸æ˜¯æŒ‡ç«‹åˆ»è¿›è¡Œä¸Šä¸‹æ–‡åˆ‡æ¢ï¼Œé¦–å…ˆè¿™é‡Œå‘ç”Ÿåœ¨ä¸­æ–­ï¼Œä¸å¯èƒ½è¿›è¡Œè¿›ç¨‹è°ƒåº¦ï¼Œæ‰€ä»¥åªèƒ½è®¾ç½®æ ‡å¿—ä½ï¼Œç­‰å¾…ä¸‹ä¸€æ¬¡ schedule çš„è°ƒç”¨å‡ºç°ï¼Œè¿›ç¨‹å°±ä¼šè¢«æ¢å‡ºã€‚
{% endhint %}

> **What is schedule\(\) function?**  
> It implements the Main Scheduler. It is defined in kernel/sched.c  
> It is called from many points in the kernel to allocate the CPU to a process other than the currently active one  
> Usually called after returning from system calls, if TIF\_NEED\_RESCHED is set for current task -[cite\_here](https://oakbytes.wordpress.com/2012/07/03/cfs-and-periodic-scheduler/)

### è¿›ç¨‹çš„å­©å­æ€ä¹ˆåŠ

æ“ä½œç³»ç»Ÿçš„æ‰€æœ‰çš„è¿›ç¨‹éƒ½æ˜¯ç”±æœ€å¼€å§‹çš„è¿›ç¨‹\( init \)è¡ç”Ÿå‡ºæ¥çš„ï¼Œå¯ä»¥è¯´ï¼Œå®ƒæ˜¯æ‰€æœ‰è¿›ç¨‹çš„çˆ¶æ¯ï¼Œè¯•æƒ³ä¸€ä¸‹ï¼Œæ¯æ¬¡æˆ‘ä»¬ fork ä¹‹åï¼Œå°±æœ‰ä¸€ä¸ªæ–°çš„å­è¿›ç¨‹æ·»åŠ åˆ°è¿è¡Œé˜Ÿåˆ—ï¼ˆå­è¿›ç¨‹è‚¯å®šæ˜¯å°±ç»ªæ€ ï¼‰ã€‚å¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ fork ä¹‹åè¦åšçš„äº‹æƒ…éƒ½æ˜¯æ‰§è¡Œä¸€ä¸ªæ–°çš„å¯æ‰§è¡Œç¨‹åºï¼Œç„¶åçˆ¶æ¯è¿›ç¨‹åˆ™ç¡çœ æˆ–è€…ç­‰å¾…å­è¿›ç¨‹çš„ä¸€äº›ä¿¡å·ï¼Œæ‰€ä»¥æˆ‘ä»¬ CFS åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„è¿›ç¨‹çš„æ—¶å€™ï¼Œå¾€å¾€æ˜¯æŠŠ Fair Key è°ƒæ•´çš„æ¯”çˆ¶è¿›ç¨‹ï¼ˆä¹Ÿå°±æ˜¯å½“å‰è¿›ç¨‹ï¼‰è¦å°ï¼Œå¦‚æ­¤ä»¥æ¥å­è¿›ç¨‹å°±å¯ä»¥å¾—åˆ°æ›´å¿«çš„è°ƒåº¦ã€‚

è€ƒè™‘ä¸€ä¸ªç¨‹åºï¼Œæ¯æ¬¡æˆ‘æ‰§è¡Œå®Œä¸€æ®µæ—¶é—´ ï¼ˆå¤§æ¦‚æ˜¯ä¸€ä¸ªæ—¶é—´ç‰‡ï¼‰ï¼Œç„¶åæˆ‘ forkï¼Œè®©æˆ‘å­è¿›ç¨‹ç»§ç»­æ‰§è¡Œï¼Œæ¥ç€æˆ‘å‘¨è€Œå¤å§‹ï¼Œé‚£æ˜¯ä¸æ˜¯è¿™ä¸ªè¿›ç¨‹æ°¸è¿œéœ¸å è¿™ CPU äº†ï¼Œåœ¨ä¹‹å‰çš„è¿›ç¨‹è°ƒåº¦å™¨éƒ½æ˜¯é€šè¿‡è®©å­è¿›ç¨‹å¾—åˆ°çˆ¶è¿›ç¨‹çš„æ—¶é—´ç‰‡çš„ä¸€åŠï¼Œé˜²æ­¢è¿™ç§æƒ…å†µçš„å‘ç”Ÿã€‚

2.6.23 æ˜¯é€šè¿‡ç»™ $$wait\_runtime$$ èµ‹å€¼ä¸€ä¸ªå°äº 0 çš„å€¼ï¼Œè¿™æ ·ä¸‹ä¸€æ¬¡æ›´æ–° Fair Key çš„æ—¶å€™ï¼Œå°±ä¼šæ¯” Fair Clock èµ°å¾—å¿«ã€‚**ï¼Œå¦‚æœä¸€ç›´æœ‰è¿›ç¨‹ä¸€ç›´åœ¨ Forkå­è¿›ç¨‹ï¼Œ é‚£ä¹ˆå­è¿›ç¨‹æ°¸è¿œå¾—ä¸åˆ°æ‰§è¡Œã€‚**

```c
/*
     * Child runs first: we let it run before the parent
     * until it reschedules once. We set up the key so that
     * it will preempt the parent:
     */
    se->fair_key = curr->fair_key -
        niced_granularity(curr, sched_granularity(cfs_rq)) - 1;

    /*
     * The statistical average of wait_runtime is about
     * -granularity/2, so initialize the task with that:
     */
    if (sysctl_sched_features & SCHED_FEAT_START_DEBIT)
        se->wait_runtime = -(sched_granularity(cfs_rq) / 2);
```

è€Œ 2.6.24 ï¼Œå¯¹äºä¸€ä¸ªæ–°çš„åˆå§‹åŒ–çš„è¿›ç¨‹ï¼Œæˆ‘ä»¬å½“å‰ç®¡ç†çš„è¿›ç¨‹çš„æœ€å°çš„ Fair Key çš„åŸºç¡€ä¸Šï¼ŒåŠ ä¸Šä¸€ä¸ªæ—¶é—´ç‰‡çš„é•¿åº¦ï¼Œ_**å­è¿›ç¨‹ä¼˜å…ˆ**_è¿™ä¸ªç†å¿µä¹Ÿå¾—å¾—åˆ°ä½“ç°ï¼Œæ‰€ä»¥æˆ‘ä»¬è¿˜å¾—æ¯”è¾ƒ æ­¤æ—¶å­è¿›ç¨‹çš„ Fair Key å’Œ çˆ¶è¿›ç¨‹çš„ æ¯”è¾ƒï¼Œä¿è¯å­è¿›ç¨‹çš„ Fair Key æ¯”çˆ¶è¿›ç¨‹å°ï¼Œå¦‚æœå¤§äº†ï¼Œåˆ™ä¸¤è€…äº¤æ¢ã€‚åœ¨å€’æ•°ç¬¬äºŒèŠ‚æœ‰æåˆ°ã€‚

{% hint style="info" %}
Fair Key å’Œ vruntime æ˜¯å¯ä»¥ç­‰ä»·æ¥ç†è§£çš„
{% endhint %}

### ä¸ºä½•é€‰æ‹©æ—©æœŸçš„ä»£ç 

è¯»è€…å¯èƒ½å‘å‘ç°ï¼Œè¿™é‡Œé€‰çš„éƒ½æ˜¯æœ€æ—© CFS å‡ºç°çš„ä»£ç ï¼ŒåŸå› åªæœ‰ä¸€ä¸ªï¼Œæ–‡æ¡£éå¸¸çš„ä¸°å¯Œï¼Œä¸€ä¸ªæ–°å…´çš„äº‹ç‰©ï¼Œè®¾è®¡è€…ä¸ºäº†è®©æ›´å¤šäººçš„ç†è§£ï¼Œè‚¯å®šå¾—å†™ä¸å°‘çš„è§£é‡Šæ–‡æ¡£ï¼Œå¯æ˜¯éšç€åæœŸçš„ä¸°å¯Œï¼Œå…¶ä¸­åŸå§”å¾€å¾€åªæœ‰æœ€ä¸»è¦çš„é‚£å‡ ä¸ªäººæ‰çœ‹å¾—æ‡‚äº†ï¼Œåªæœ‰äº†è§£äº†æœ€åˆçš„æ¨¡æ ·ï¼Œæ‰èƒ½æŒæ¡åé¢çš„ï¼Œå› ä¸ºä¸»è¦çš„æ€æƒ³ä¸ä¼šæ”¹å˜ï¼Œæ‰€ä»¥é˜…è¯»å†…æ ¸çš„ä»£ç ä¹Ÿæ˜¯ä»æ—©æœŸçš„ä»£ç å¼€å§‹é˜…è¯»ã€‚

è‡³äºåæœŸå‡ºç°çš„ vruntime æœ¬è´¨å…¶å®å°±æ˜¯ Fair Clockï¼Œå®ƒçš„æ€æƒ³ä»ç„¶æ²¡æœ‰æ”¹å˜ï¼Œå¯èƒ½åšäº†ä¸€äº›ä¿®æ”¹ï¼Œç»è¿‡æµ‹è¯•ä¹‹åå¾—åˆ°æœ€ç®€å•æœ€ä¼˜çš„ä¸€ä¸ªç®—æ³•ã€‚ä½†æ˜¯å¦‚æœç›´æ¥å¼€å§‹çœ‹é‚£é‡Œçš„ä»£ç ï¼Œåˆ™ä¼šéå¸¸çš„éš¾ä»¥ç†è§£ã€‚

### ä»¥ nice = 0 å’Œ nice = 1 çš„ä¸¤ä¸ªè¿›ç¨‹ä¸ºä¾‹

å¯èƒ½ä¸Šé¢çš„è§£é‡Šä»æœ‰è¯»è€…éš¾ä»¥ç†è§£ï¼Œå› ä¸ºæˆ‘çš„è¯­æ–‡å¹¶ä¸å¥½ï¼Œæ¥ä¸‹æ¥å°±ä»¥ä¸€ä¸ªå®é™…çš„ä¾‹å­å‡ºå‘ï¼Œå‡è®¾å­˜åœ¨ t1 t2 ä¸¤ä¸ªè¿›ç¨‹ï¼Œå®ƒä»¬çš„ nice å€¼åˆ†åˆ«æ˜¯ 0 å’Œ 1ã€‚

å‡è®¾ç°åœ¨ CFS è¿è¡Œäº†ä¸€æ®µæ—¶é—´ï¼Œç°åœ¨ Fair Clock ä¸º 100

ä¿©ä¸ªè¿›ç¨‹åŒæ—¶è¿›å…¥äº†é˜Ÿåˆ—ï¼Œç°åœ¨ _**rq**_ çš„ $$total\_weight$$ ä¸º 1844ï¼Œå¹¶ä¸”å®ƒä»¬çš„ Fair Key åˆå§‹åŒ– ä¸º 100ï¼ˆå¿½ç•¥ä¸¤è€…è¿›æ¥çš„å…ˆåï¼Œéƒ½æ— æ‰€è°“è¿™é‡Œ ï¼‰

æˆ‘ä»¬å†å‡è®¾ï¼Œç³»ç»Ÿçš„å»¶è¿Ÿä¸º 100msï¼Œæ—¶é—´ä¸­æ–­æ˜¯ 5msï¼Œåªæœ‰è¿™ä¸¤ä¸ªè¿›ç¨‹æ˜¯å°±ç»ªæ€

ç°åœ¨ CFS é€‰æ‹©äº† t1 è¿è¡Œï¼Œå…¶å® t2 ä¹Ÿæ— æ‰€è°“ï¼Œéƒ½ä¸€æ ·

5ms åï¼Œæ—¶é—´ä¸­æ–­ï¼Œt1 çš„ Fair Key æ›´æ–°ä¸º 105ï¼ˆè¿™é‡Œå‡è®¾åˆå§‹ wait\_runtime ä¸º0ï¼‰

$$
Fair\_Clock ~+= ~ \frac{1024}{t->\_weight} * delta
$$

æ¥ç€ t1 é‡æ–°æ’å…¥é˜Ÿåˆ—ä¸­ï¼Œå‘ç°å·²ç»ä¸æ˜¯ Fair Key æœ€å°çš„é‚£ä¸ªè¿›ç¨‹ï¼Œäºæ˜¯è®¡ç®—ä¸¤è€… Fair Key çš„å·®ï¼Œå¾—åˆ° 5ï¼Œè€Œ t1 è¿›ç¨‹ç›®å‰æ‰§è¡Œäº† 5msï¼Œå®ƒåº”è¯¥æ‰§è¡Œ

$$
delta\_mine = \frac{t1->weight}{total\_weight} *100ms
$$

ä»£å…¥å¾—åˆ° 55msï¼Œå¹¶ä¸”ç°åœ¨ Fair Key çš„å·®å€¼ä»…ä¸º 5ï¼Œæˆ‘ä»¬è®¡ç®— gran = 25

$$
gran = latency/n - latency/n/n
$$

$$
niced\_granularity = \left\{ \begin{array}{ll}
\frac{gran~*~1024}{weight} & \textrm{if weight>=~1024}\\
& \\
\frac{gran~*~weight}{1024} & \textrm{if weight < 1024}\\
\end{array} \right.
$$

å¦‚æ­¤å¾ªç¯5æ¬¡ï¼Œå‘ç°äº† ä¸¤è€…å·®å¤§äº25ï¼Œæ­¤æ—¶ Fair Clock ä¸º 130 = t1-&gt;Fair Key ï¼Œè€Œ t2 ä»æ˜¯æœ€åˆçš„ 100ï¼Œæ‰€ä»¥æˆ‘ä»¬è®¤ä¸ºæ­¤æ—¶è¿›ç¨‹å¯ä»¥åˆ‡æ¢äº†ã€‚å…¶å®è¿™é‡Œå¹¶ä¸å¤ªå¥½å¯¹å§ï¼Œæ˜æ˜è¿›ç¨‹ä»æœ‰ 30ms å¯ä»¥ä½¿ç”¨ï¼Œæ‰€ä»¥åé¢ 2.6.24.7 çš„ä»£ç ï¼Œå°±å·²ç»æ˜¯åˆ¤æ–­**å®ƒæ˜¯å¦è¶…è¿‡è‡ªå·±åº”è¯¥å¾—åˆ°çš„æ—¶é—´**äº†ï¼Œæˆ‘è§‰å¾—åªæœ‰é€‚åˆä¸é€‚åˆï¼Œæ²¡æœ‰å¥½ä¸ä¸å¥½ï¼Œä¸Šé¢è¿™ä¸ªåˆ¤æ–­å…¶å®å¯ä»¥è®©åªæœ‰ä¿©ä¸ªè¿›ç¨‹çš„è¿è¡Œçš„CPUçš„å»¶è¿Ÿéƒ½å¾ˆä½ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨ä¿è¯äº† 100ms å»¶è¿Ÿçš„å‰æä¸‹ï¼Œåˆè¿›ä¸€æ­¥**å‹ç¼©**äº†è¿›ç¨‹çš„æ—¶é—´ç‰‡ã€‚

t1-&gt;fair\_key = 130; t2-&gt;fair\_key = 100

æˆ‘ä»¬å‡è®¾5msä¹‹åï¼Œscheduleå‡½æ•°è¢«è°ƒç”¨ï¼Œæ‰€ä»¥ t1-&gt;fair\_key = 135

CFS ç»ˆäºé€‰æ‹©äº† t2 è¿è¡Œï¼Œ5ms ä¹‹åï¼Œ t2-&gt;weight = 820

$$
Fair\_Clock ~+= ~ \frac{1024}{t->\_weight} * delta
$$

æ‰€ä»¥ 5ms ä¹‹åï¼Œ Fair Clock = 135 + 6 = 141 ï¼Œå®ƒçš„ gran æ˜¯ 25 \* 1024 / 820 = 31

{% hint style="info" %}
åŒæ ·æ˜¯è¿è¡Œ 5msï¼Œä½†æ˜¯ä½ç‰¹æƒçš„è¿›ç¨‹å´è®© Fair Clock â€œèµ°â€çš„æ›´å¿«
{% endhint %}

æ³¨æ„ï¼š ç°åœ¨ t1 çš„ Fair Key å·²ç»æ¯” t2 çš„è¦å°äº†ï¼Œä½†æ˜¯å¹¶æ²¡æœ‰è¶…è¿‡ granï¼Œä»¥åŠå®ƒèƒ½è¿è¡Œçš„æ—¶é—´ 45ms

ä¸‹ä¸€ä¸ªæ—¶é—´ä¸­æ–­: t2-&gt;Fair Key = 147 = Fair Clockï¼Œ ä¸¤è€…å·®ä¸º $$delta = 147 -135 = 12$$

... t2-&gt;Fair Key = 153 = Fair Clock ï¼Œ $$delta = 12 +6 = 18$$

... $$delta = 24$$ ï¼Œæ­¤æ—¶è¿›ç¨‹è¿è¡Œäº† 20ms

... $$delta = 30$$

... $$delta = 36$$ è¿›ç¨‹è¿è¡Œäº† 30msï¼Œt2-&gt;Fair Key = 171 = Fair Clock

è½®åˆ°äº† t1 å‡è®¾ï¼Œ 5ms ä¹‹å è¿›ç¨‹å¼€å§‹è°ƒåº¦ï¼Œåˆ™ t2-&gt;Fair Key = 177 = Fair Clockï¼Œè¿›ç¨‹è¿è¡Œäº† 35ms

æ­¤æ—¶ CPU å ç”¨æ¯”æ˜¯ 1:1 ï¼Œ t1-&gt;gran = 25ï¼Œæ‰€ä»¥ 30ms ä»ç„¶ä¼šè½®åˆ° t2 è¿è¡Œ

æ³¨æ„åˆ°å®ƒä»¬çš„æ¯”å€¼å…¶å®å°±æ ¹æ®å®ƒä»¬çš„é‡é‡å¾—åˆ°ï¼Œæ‰€ä»¥è¿™æ ·ä¸‹å»ä¸€ç›´ä¼šæ˜¯ 1:1ï¼Œè™½ç„¶

Fair Clock å¢é•¿é€Ÿåº¦ä¸ä¸€æ ·ï¼Œä½†æ˜¯ä¸¤è€…èƒ½å¿å—çš„ å·®å€¼ï¼ˆniced\_granï¼‰ ä¹Ÿä¸ä¸€æ ·ï¼Œ

æˆ‘ä»¬æ˜¯ä¸æ˜¯å¿˜äº†ä»€ä¹ˆï¼Œwait\_runtime !

æ¯ä¸€ä¸ª 5msï¼Œè¿›ç¨‹çš„ wait\_runtime ä¼šè¿™æ ·å¢åŠ ï¼Œdelta = 5ms

$$
task->wait\_runtime ~+= ~\frac{task->weight -1024}{total\_weight}*delta
$$

{% hint style="info" %}
CFS æ˜¯ä»¥çº³ç§’ä¸ºå•ä½çš„ï¼Œæ‰€ä»¥è¿™çœ‹èµ·æ¥æ•°å€¼ä¼šå¾ˆå°
{% endhint %}

$$
Fair\_Key = Fair\_Clock - wait\_runtime
$$

å¯¹äº t1 ä»–çš„ weight æ­£å¥½ä¸º 1024ï¼Œæ‰€ä»¥æ²¡æœ‰è¡¥å¿ï¼Œä½†æ˜¯å¯¹äº t2ï¼Œå®ƒçš„ wait\_runtime ä¼šå˜å°ï¼Œå½“ç„¶æ˜¯æœ‰ä¸ªä¸Šé™ï¼Œè¿™æ ·å®ƒçš„ Fair Key å°±èµ°åœ¨äº† Fair Clock çš„å‰æ–¹ã€‚å½“ç„¶è¿™é‡Œä»¥ 5ms è®¡ç®—ï¼Œå®é™…ä¸Šåªæœ‰0.5ï¼Œå› ä¸ºæˆ‘æ˜¯ä»¥æ¯«ç§’ä¸ºå•ä½ï¼Œä½†æ˜¯è®°ä½å®ƒæ˜¯_**ç´¯è®¡é‡**_ï¼Œé‚£ä¹ˆå®é™…ä¸Šï¼Œå®ƒé™¤äº†è®© Fair Clock çš„æ›´å¿«ï¼Œå®ƒåŒæ—¶è¿˜è®©è‡ªå·±çš„ Fair Key ä¸€å®šæ¯” Clock å¤§ä¸€ç‚¹ã€‚

{% hint style="info" %}
å¦‚æœè¿›ç¨‹ç¡çœ ï¼Œé‚£ä¹ˆ wait\_runtime ä¼šå˜å¤§ï¼Œè¿™æ ·å°±èµ°åœ¨äº† Clock çš„åé¢
{% endhint %}

ä¸¾è¿™ä¸ªä¾‹å­ï¼Œå°±æ˜¯è®©å¤§å®¶äº†è§£ CFS çš„å®è´¨å°±æ˜¯ç»´æŠ¤äº†ä¸€ä¸ª Fair Clockï¼Œä»¥åŠè°ƒæ•´å…¬å¹³åçš„æ¯ä¸ªè¿›ç¨‹éƒ½ä¼šæœ‰çš„ Fair Keyã€‚é•¿æ—¶é—´æœªæ‰§è¡Œçš„è¿›ç¨‹å¿…ç„¶é©¬ä¸Šå¾—åˆ° CPU çš„ä½¿ç”¨æƒã€‚

å®é™…çš„å®ç°è¿˜æœ‰æ¯”è¾ƒå¤šçš„å‚æ•°ï¼Œä½†æ˜¯å¤ªé«˜æ·±è«æµ‹äº†ï¼Œä½†æ˜¯æˆ‘å·²ç»äº†è§£äº†å®é™…çš„æ€æƒ³ï¼Œå°±æ˜¯ç»´æŠ¤ä¸€ä¸ªå…¬å¹³çš„æ—¶é’Ÿï¼Œå¦‚æœè®©æˆ‘æ¥å®ç°ï¼Œæˆ‘ä¼šç®€å•çš„åˆ¤æ–­å½“å‰çš„è¿›ç¨‹æ‹¥æœ‰å¤šå°‘çš„æ—¶é—´ï¼Œå¦‚æœæ²¡æœ‰è¶…è¿‡ï¼Œæ¥ç€åˆ¤æ–­ï¼Œå¦‚æœå½“å‰å·²ç»ä¸æ˜¯æœ€å°çš„ Fair Keyï¼Œæˆ‘ä¼šè®©é«˜ç‰¹æƒçš„è¿›ç¨‹æ‰€èƒ½æ¥å—çš„å·®å€¼å¤§ä¸€äº›ï¼Œè€Œä¸æ˜¯ä¸Šé¢åªè®© nice = 0 çš„èƒ½è·å¾—æœ€å¤§çš„ niced\_granï¼Œæ¯•ç«Ÿæ˜¯ç‰¹æƒè¿›ç¨‹ï¼Œç„¶å wait\_runtime è®¾è®¡ä¸ºä¸€ä¸ªç´¯è®¡é‡ï¼Œæ¯å½“è¿›ç¨‹è¦è¢«åˆ‡æ¢çš„æ—¶å€™æ›´æ–°ï¼Œæ›´æ–°ä¸ºå®ƒè¿™æ¬¡è·ç¦»å®ƒåº”è¯¥æ‰§è¡Œçš„æ—¶é—´çš„å·® å¯¹åº”çš„ ä¸€ä¸ªæƒè¡¡çš„å€¼ã€‚

{% hint style="info" %}
ä¸Šé¢çš„ä»£ç æ¯æ¬¡æ‰§è¡Œéƒ½æ›´æ–°ä¸€æ¬¡ï¼Œæ—¢ç„¶ä¿è¯äº† Fair Clock çš„å¢é•¿ä¸ä¸€è‡´ï¼Œåˆè®¾è®¡è¿™ä¸ªï¼Œåªå­˜åœ¨ä¸€ä¸ªæˆ‘è§‰å¾—å³å¯ã€‚
{% endhint %}

{% hint style="info" %}
åœ¨ 2.6.24 ä¹‹åï¼Œå°±æ˜¯ç›´æ¥è®©è¿›ç¨‹è¿è¡Œåˆ°è‡ªå·±çš„æ—¶é—´ç‰‡ç›´åˆ°ç»“æŸï¼Œå¹¶ä¸”ï¼Œç‰¹æƒè¿›ç¨‹è®© vunrime\( Fair Clock\) å¢é•¿çš„æ…¢ã€‚å¹¶ä¸”ä¹Ÿæ²¡æœ‰ wait\_runtime ï¼Œå› ä¸ºé»˜è®¤æ˜¯æ‰§è¡Œå®Œæ—¶é—´ç‰‡æ‰åˆ‡æ¢ï¼Œç„¶åç¡çœ çš„è¿›ç¨‹å¾—åˆ° vruntime\(Fair Key\) = minimal\_vruntime - ä¸€ä¸ªæ—¶é—´ç‰‡ çš„å€¼ï¼Œä¹Ÿå°±æ˜¯è¯´è®©ç¡çœ çš„è¿›ç¨‹æ˜¯å½“å‰æœ€éœ€è¦CPUçš„ã€‚
{% endhint %}

## CFS çš„å®ç° - ä»¥ 2.6.23 ä¸ºä¾‹

{% hint style="info" %}
Fair Key ç»´æŠ¤åœ¨ä¸€ä¸ªçº¢é»‘æ ‘ï¼Œå…¶å®æ˜¯ä»€ä¹ˆç»“æ„éƒ½æ— æ‰€è°“ï¼Œè¿™é‡Œä¸é˜è¿°äº†ã€‚
{% endhint %}

è¿™é‡Œä¸åœ¨è¿›è¡Œä¸åœçš„ä»£ç å¤åˆ¶ç²˜è´´ï¼Œæˆ‘åªä¼šæä¸€äº›å…³é”®çš„åœ°æ–¹ï¼Œä¹Ÿæ˜¯è‡ªå·±æœ€å¼€å§‹é˜…è¯»çš„ä»£ç å›°æƒ‘çš„å‡ ä¸ªåœ°æ–¹ã€‚

æ¯ä¸€æ¬¡æ—¶é’Ÿä¸­æ–­ï¼Œtick

```c
/*
 * scheduler tick hitting a task of our scheduling class:
 */
static void task_tick_fair(struct rq *rq, struct task_struct *curr)
{
    struct cfs_rq *cfs_rq;
    struct sched_entity *se = &curr->se;

    for_each_sched_entity(se) {
        cfs_rq = cfs_rq_of(se);
        entity_tick(cfs_rq, se);
    }
}

static void entity_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr)
{
    struct sched_entity *next;

    /*
     * Dequeue and enqueue the task to update its
     * position within the tree:
     */
    dequeue_entity(cfs_rq, curr, 0);
    enqueue_entity(cfs_rq, curr, 0);

    /*
     * Reschedule if another task tops the current one.
     */
    next = __pick_next_entity(cfs_rq);
    if (next == curr)
        return;

    __check_preempt_curr_fair(cfs_rq, next, curr,
            sched_granularity(cfs_rq));
}

/*
 * Preempt the current task with a newly woken task if needed:
 */
static void
__check_preempt_curr_fair(struct cfs_rq *cfs_rq, struct sched_entity *se,
              struct sched_entity *curr, unsigned long granularity)
{
    s64 __delta = curr->fair_key - se->fair_key;
    unsigned long ideal_runtime, delta_exec;

    /*
     * ideal_runtime is compared against sum_exec_runtime, which is
     * walltime, hence do not scale.
     */
    ideal_runtime = max(sysctl_sched_latency / cfs_rq->nr_running,
            (unsigned long)sysctl_sched_min_granularity);

    /*
     * If we executed more than what the latency constraint suggests,
     * reduce the rescheduling granularity. This way the total latency
     * of how much a task is not scheduled converges to
     * sysctl_sched_latency:
     */
    delta_exec = curr->sum_exec_runtime - curr->prev_sum_exec_runtime;
    if (delta_exec > ideal_runtime)
        granularity = 0;

    /*
     * Take scheduling granularity into account - do not
     * preempt the current task unless the best task has
     * a larger than sched_granularity fairness advantage:
     *
     * scale granularity as key space is in fair_clock.
     */
    if (__delta > niced_granularity(curr, granularity))
        resched_task(rq_of(cfs_rq)->curr);
}
```

å¯ä»¥çœ‹åˆ°åˆ¤æ–­éå¸¸çš„å¤æ‚ï¼Œè·Ÿæˆ‘ä»¬ä¸Šé¢è¯´çš„ç±»ä¼¼ï¼Œå°±ä¸è§£é‡Šäº†ï¼Œå½“ **fork\(\)** æ—¶

```c
/*
 * Share the fairness runtime between parent and child, thus the
 * total amount of pressure for CPU stays equal - new tasks
 * get a chance to run but frequent forkers are not allowed to
 * monopolize the CPU. Note: the parent runqueue is locked,
 * the child is not running yet.
 */
static void task_new_fair(struct rq *rq, struct task_struct *p)
{
    struct cfs_rq *cfs_rq = task_cfs_rq(p);
    struct sched_entity *se = &p->se, *curr = cfs_rq_curr(cfs_rq);

    sched_info_queued(p);

    update_curr(cfs_rq);
    update_stats_enqueue(cfs_rq, se);
    /*
     * Child runs first: we let it run before the parent
     * until it reschedules once. We set up the key so that
     * it will preempt the parent:
     */
    se->fair_key = curr->fair_key -
        niced_granularity(curr, sched_granularity(cfs_rq)) - 1;
    /*
     * The first wait is dominated by the child-runs-first logic,
     * so do not credit it with that waiting time yet:
     */
    if (sysctl_sched_features & SCHED_FEAT_SKIP_INITIAL)
        se->wait_start_fair = 0;

    /*
     * The statistical average of wait_runtime is about
     * -granularity/2, so initialize the task with that:
     */
    if (sysctl_sched_features & SCHED_FEAT_START_DEBIT)
        se->wait_runtime = -(sched_granularity(cfs_rq) / 2);

    __enqueue_entity(cfs_rq, se);
}
```

æœ€é‡è¦çš„è®°è´¦å‡½æ•°ï¼Œæ¯ä¸€æ¬¡æ’å…¥å’Œå‡ºåˆ—ï¼Œéƒ½ä¼šè°ƒç”¨

```c
/*
 * Update the current task's runtime statistics. Skip current tasks that
 * are not in our scheduling class.
 */
static inline void
__update_curr(struct cfs_rq *cfs_rq, struct sched_entity *curr)
{
    unsigned long delta, delta_exec, delta_fair, delta_mine;
    struct load_weight *lw = &cfs_rq->load;
    unsigned long load = lw->weight;

    delta_exec = curr->delta_exec;
    schedstat_set(curr->exec_max, max((u64)delta_exec, curr->exec_max));

    curr->sum_exec_runtime += delta_exec;
    cfs_rq->exec_clock += delta_exec;

    if (unlikely(!load))
        return;

    delta_fair = calc_delta_fair(delta_exec, lw);
    delta_mine = calc_delta_mine(delta_exec, curr->load.weight, lw);

    if (cfs_rq->sleeper_bonus > sysctl_sched_min_granularity) {
        delta = min((u64)delta_mine, cfs_rq->sleeper_bonus);
        delta = min(delta, (unsigned long)(
            (long)sysctl_sched_runtime_limit - curr->wait_runtime));
        cfs_rq->sleeper_bonus -= delta;
        delta_mine -= delta;
    }

    cfs_rq->fair_clock += delta_fair;
    /*
     * We executed delta_exec amount of time on the CPU,
     * but we were only entitled to delta_mine amount of
     * time during that period (if nr_running == 1 then
     * the two values are equal)
     * [Note: delta_mine - delta_exec is negative]:
     */
    add_wait_runtime(cfs_rq, curr, delta_mine - delta_exec);
}
```

{% hint style="info" %}
æ¯æ¬¡æ—¶é—´ä¸­æ–­ï¼Œå½“å‰è¿›ç¨‹éƒ½ä¼šé‡æ–°æ’å…¥é˜Ÿåˆ—ï¼Œä»¥æ›´æ–°ä¿¡æ¯ã€‚
{% endhint %}

## vruntime æ—¶æœŸçš„ CFS

å‰é¢ä¹Ÿä¸æ­¢ä¸€æ¬¡çš„æåˆ°ï¼Œvruntime å’Œ Fair Key æ˜¯ä¸€ä¸ªæ¦‚å¿µï¼Œä» 2.6.24 ä¹‹å CFS å¾—åˆ°äº†ç®€åŒ–ï¼Œå»é™¤äº†æŒºå¤šä¸å¿…è¦çš„æ¯”è¾ƒï¼Œä¹Ÿå¢åŠ äº†ä¸€äº›å®‰å…¨æ£€æŸ¥ï¼Œæ€»ä½“æ¥è¯´æ›´å®¹æ˜“é˜…è¯»ã€‚

1. é¦–å…ˆåœ¨è°ƒåº¦æ–¹é¢ï¼Œæ­£å¸¸æƒ…å†µï¼Œåªæœ‰å½“è¿›ç¨‹çš„æ—¶é—´ç‰‡æ¶ˆè€—å®Œæ¯•çš„æƒ…å†µä¸‹æ‰ä¼šé‡æ–°è°ƒåº¦ã€‚
2. å½“ä¸€ä¸ªè¿›ç¨‹è‹é†’ï¼Œæˆ–è€…ä¸€ä¸ªæ–°çš„çº¿ç¨‹åˆ›å»ºä¼šè°ƒç”¨ preemption ç›¸å…³å‡½æ•°
3. ç¡çœ çš„è¿›ç¨‹å¾—åˆ°çš„ bonusï¼Œéƒ½é€šè¿‡ vruntime å®ç°

```c
/*
 * Preempt the current task with a newly woken task if needed:
 *   
 */
static void
check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr)
{
    unsigned long ideal_runtime, delta_exec;

    ideal_runtime = sched_slice(cfs_rq, curr);
    delta_exec = curr->sum_exec_runtime - curr->prev_sum_exec_runtime;
    if (delta_exec > ideal_runtime)
        resched_task(rq_of(cfs_rq)->curr);
}
```

sched\_slice æ˜¯æ ¹æ® weight è·å–è¿›ç¨‹åº”è¯¥è¿è¡Œçš„æ—¶é—´ç‰‡é•¿åº¦ï¼Œå‚è€ƒ Fair Clocké‚£ä¸€èŠ‚æåˆ°çš„è®¡ç®—æ–¹æ³•ï¼Œåœ¨æ­£å¸¸çš„è°ƒåº¦æƒ…å†µä¸‹è¿›ç¨‹éƒ½è€—å°½è‡ªå·±çš„ CPU æ—¶é—´ã€‚

```c
/*
 * Preempt the current task with a newly woken task if needed:
 */
static void check_preempt_wakeup(struct rq *rq, struct task_struct *p)
{
    struct task_struct *curr = rq->curr;
    struct cfs_rq *cfs_rq = task_cfs_rq(curr);
    struct sched_entity *se = &curr->se, *pse = &p->se;
    unsigned long gran;
    ...

    gran = sysctl_sched_wakeup_granularity;  // default = 10ms
    if (unlikely(se->load.weight != NICE_0_LOAD))
        gran = calc_delta_fair(gran, &se->load);

    if (pse->vruntime + gran < se->vruntime)
        resched_task(curr);
}
```

ç®€å•ç‚¹ç†è§£ï¼Œå¦‚æœè¿™ä¸ªè¿›ç¨‹å·²ç»ç¡çœ è¶…è¿‡ 10ms äº†ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±é©¬ä¸Šæ ‡è®°è¿™ä¸ªè¿›ç¨‹æ˜¯å¯åˆ‡æ¢çš„ï¼Œç­‰ä¸‹æ¬¡ schedule\(\) è°ƒç”¨å°±ä¼šå°†è¿™ä¸ªè¿›ç¨‹åˆ‡æ¢å‡ºCPUã€‚è¿™ä¸ªå‡½æ•°åœ¨ **try\_to\_wake\_up\(\)** å’Œ **wake\_up\_new\_task\(\)** ä¸­å‡æœ‰è°ƒç”¨ï¼Œè®¾è®¡æŠ¢å æ˜¯ä¸ºäº†æå‡ interactivityï¼Œä¸èµ˜è¿°äº†ã€‚

```c
static void
place_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int initial)
{
    u64 vruntime;
    ...
    ...        
    // for fork, initial = 1, else = 0
    vruntime = cfs_rq->min_vruntime;
    /*
     * The 'current' period is already promised to the current tasks,
     * however the extra weight of the new task will slow them down a
     * little, place the new task so that it fits in the slot that
     * stays open at the end.
     */
    if (initial && sched_feat(START_DEBIT))
        vruntime += sched_vslice_add(cfs_rq, se);

    if (!initial) {
        /* sleeps upto a single latency don't count. */
        if (sched_feat(NEW_FAIR_SLEEPERS) && entity_is_task(se))
            vruntime -= sysctl_sched_latency;

        /* ensure we never gain time by being placed backwards. */
        vruntime = max_vruntime(se->vruntime, vruntime);
    }

    se->vruntime = vruntime;
}
```

çœ‹ï¼Œå½“è¿›ç¨‹è‹é†’çš„æ—¶å€™ï¼Œè¿›ç¨‹çš„ vrunime æå¤§å¯èƒ½æ¯”é˜Ÿåˆ—é‡Œæœ€å°çš„ vruntime è¿˜è¦å°ï¼Œæ³¨æ„æ­¤æ—¶è¿›ç¨‹è¿˜æ²¡æœ‰å…¥åˆ—ï¼Œæ‰€ä»¥å®ƒåœ¨ä¸‹æ¬¡è°ƒåº¦ä¹‹åå¯ä»¥å¾—åˆ°æ‰§è¡Œã€‚è€Œæ™®é€šçš„è¿›ç¨‹å¿…ç„¶æ˜¯æ¯”æœ€å°çš„ vruntime è¦å¤§çš„ã€‚æ³¨é‡Šä¹Ÿå¾ˆæ¸…æ¥š

```c
vruntime = max_vruntime(se->vruntime, vruntime);
```

è®°è´¦å‡½æ•°æ˜¯ç±»ä¼¼çš„ï¼Œå°±ä¸å¤åˆ¶äº†ã€‚

## æœ« - äº¦æ˜¯åº

èŠ±è¿™ä¹ˆé•¿çš„ç¯‡å¹…ä»‹ç»ï¼Œå…¶å®æœ€ç»ˆç›®çš„åªæœ‰ä¸€ä¸ªï¼Œç†è§£ä¸ºä»€ä¹ˆå¯ä»¥ç²¾ç¡®æ§åˆ¶è¿›ç¨‹ä½¿ç”¨CPUçš„æ—¶é—´ï¼Œè¿™é‡Œæ˜¯é€šè¿‡ weight å®ç°çš„ï¼Œä¸‹ä¸€ç« æ§åˆ¶ç»„ç›¸å…³çŸ¥è¯†ï¼Œä¸»è§’ç»ˆäºæ¥äº†ã€‚

### References

* [the plot thicken](https://lwn.net/Articles/230574/)
* [FAQ style of CFS](https://oakbytes.wordpress.com/2012/06/06/linux-scheduler-introduction/)
* [CFS - è°ƒåº¦](https://juejin.im/post/5a97c9025188255579180e43#heading-13)
* [Inside the Linux 2.6 Completely Fair Scheduler](https://developer.ibm.com/tutorials/l-completely-fair-scheduler/)
* [Linux kernel scheduler](https://helix979.github.io/jkoo/post/os-scheduler/)
* [CFS design](http://people.redhat.com/mingo/cfs-scheduler/sched-design-CFS.txt)

